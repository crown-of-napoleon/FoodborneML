{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = yaml.load(open('cbow_setup_base_config.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_setup': {'setup_config': {'dev_portion': 0.2,\n",
       "   'lowercase': True,\n",
       "   'normalize_vectors': True,\n",
       "   'pretrained_vectors': '../data/word_vectors/trimmed_glove.840B.300d.txt',\n",
       "   'response_key': 'is_foodborne',\n",
       "   'split_random_seed': 0,\n",
       "   'train_regime': 'gold',\n",
       "   'trim_vector_file': False},\n",
       "  'setup_file': 'chainer_data_setup.py'},\n",
       " 'description': 'First we load normalized glove vectors. The doc rep is just the sum of the word vectors',\n",
       " 'email': 'teffland@cs.columbia.edu',\n",
       " 'model_setup': {'setup_config': {'composition_func': 'sum',\n",
       "   'example': 'config option because it must be nonempty'},\n",
       "  'setup_file': 'cbow_model_setup.py'},\n",
       " 'mongo_config': {'database': 'experiments',\n",
       "  'host': 'teffland.cs.columbia.edu',\n",
       "  'port': 27017,\n",
       "  'username': 'tom'},\n",
       " 'random_seed': 0,\n",
       " 'results_dir_prefix': 'chainer_experiments/',\n",
       " 'task': 'DOHMH: Yelp is foodborne?',\n",
       " 'title': 'CBOW Test Gold Regime',\n",
       " 'trainer_setup': {'setup_config': {'adam_alpha': 0.001,\n",
       "   'batch_size': 256,\n",
       "   'checkpoint_trigger': [1, 'epoch'],\n",
       "   'early_stop_patience': 10,\n",
       "   'evaluation_trigger': [1, 'epoch'],\n",
       "   'freeze_embeddings': True,\n",
       "   'l2_coef': 1.0,\n",
       "   'max_examples': 100,\n",
       "   'n_epoch': 50},\n",
       "  'setup_file': 'chainer_trainer_setup.py'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from chainer_data_setup import setup as data_setup\n",
    "from cnn_model_setup import setup as model_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "baseline_experiment_util.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  old_biased['is_foodborne'] = old_biased['is_foodborne'].map({'Yes':1, 'No':0})\n",
      "baseline_experiment_util.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  new_biased['is_foodborne'] = new_biased['is_foodborne'].map({'Yes':1, 'No':0})\n",
      "baseline_experiment_util.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  old_biased['is_multiple'] = old_biased['is_multiple'].map({'Yes':1, 'No':0})\n",
      "baseline_experiment_util.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  new_biased['is_multiple'] = new_biased['is_multiple'].map({'Yes':1, 'No':0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pad token to have a zeros embeddings\n",
      "Pretrained coverage: 26372/31173 = 84.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2017-07-01 02:26:59,400: chainer_data_setup: 9252 Training examples, 2314 Dev, 2975 Test\n"
     ]
    }
   ],
   "source": [
    "data_results = data_setup(config['data_setup']['setup_config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_results = model_setup(config['model_setup']['setup_config'], data_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred = model_results['predictor_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vocab = data_results['token_vocab']\n",
    "# xs = vocab.seqs2idx([datum['text'] for datum in data_results['train_data'][:10]], as_array=True)\n",
    "# ys = [datum['label'] for datum in data_results['train_data'][:10]]\n",
    "# ws = [datum['weight'] for datum in data_results['train_data'][:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer.dataset import concat_examples\n",
    "import chainer as ch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ..., 0 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    4719\n",
       "0    4533\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([d['ys'] for d in data_results['train_data']])\n",
    "print a\n",
    "import pandas as pd\n",
    "pd.Series(a).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [len(x) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pred(concat_examples([x.astype(np.int32) for x in xs], padding=vocab.ipad)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# optimizer = ch.optimizers.Adam(alpha=.01)\n",
    "# optimizer.setup(model_results['loss_model'])\n",
    "# train_iter = ch.iterators.SerialIterator(data_results['train_data'][:100],\n",
    "#                                              64, shuffle=True, repeat=True)\n",
    "# concat_and_pad = lambda x, device:ch.dataset.concat_examples(x, device,\n",
    "#         padding=vocab.ipad)\n",
    "# updater = ch.training.StandardUpdater(train_iter, optimizer, converter=concat_and_pad)\n",
    "# print updater._optimizers['main'].target\n",
    "# trainer = ch.training.Trainer(updater, (1,'epoch'))\n",
    "# trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concat_and_pad(train_iter.next(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vars(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from chainer_monitor.run_experiment import run_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2017-07-01 05:00:00,484: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git commit -a -m \"auto commit tracked files for new experiment: chainer_experiments/Jul-01-2017-05.00.457058_experiment\" --allow-empty'>: starting process\n",
      "[INFO] 2017-07-01 05:00:00,538: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git commit -a -m \"auto commit tracked files for new experiment: chainer_experiments/Jul-01-2017-05.00.457058_experiment\" --allow-empty', pid 90360>: process started\n",
      "[INFO] 2017-07-01 05:00:00,696: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git commit -a -m \"auto commit tracked files for new experiment: chainer_experiments/Jul-01-2017-05.00.457058_experiment\" --allow-empty', pid 90360>: process completed\n",
      "[INFO] 2017-07-01 05:00:00,699: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD'>: starting process\n",
      "[INFO] 2017-07-01 05:00:00,722: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 90363>: process started\n",
      "[INFO] 2017-07-01 05:00:00,729: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 90363>: process completed\n",
      "[INFO] 2017-07-01 05:00:00,730: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 90363>: process completed\n",
      "[INFO] 2017-07-01 05:00:00,731: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 90363>: process completed\n",
      "[INFO] 2017-07-01 05:00:00,737: chainer_monitor.run_experiment: Loading dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pad token to have a zeros embeddings\n",
      "Pretrained coverage: 26372/31173 = 84.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2017-07-01 05:00:49,899: data_setup: 9252 Training examples, 2314 Dev, 2975 Test\n",
      "[INFO] 2017-07-01 05:00:49,958: chainer_monitor.run_experiment: Setting up models\n",
      "[INFO] 2017-07-01 05:00:50,039: chainer_monitor.run_experiment: Setting up training\n",
      "[INFO] 2017-07-01 05:00:50,102: chainer_monitor.run_experiment: Saving experiment configuration\n",
      "[INFO] 2017-07-01 05:00:50,286: chainer_monitor.run_experiment: Running trainer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time  epoch       iteration   main/loss   main/aupr   validation/main/aupr\n",
      "\u001b[J32.4295       0           1           0.755534    0.436171                          \n",
      "\u001b[J32.741        0           1           0.755534    0.436171                          \n",
      "\u001b[J64.9889       0           2           0.679924    0.647839                          \n",
      "\u001b[J65.0827       0           2           0.679924    0.647839                          \n",
      "\u001b[J94.3269       0           3           0.741165    0.478865                          \n",
      "\u001b[J94.4331       0           3           0.741165    0.478865                          \n",
      "\u001b[J125.72        0           4           0.693318    0.570424                          \n",
      "\u001b[J125.804       0           4           0.693318    0.570424                          \n",
      "\u001b[J152.866       0           5           0.680038    0.643823                          \n",
      "\u001b[J153.003       0           5           0.680038    0.643823                          \n",
      "\u001b[J187.467       0           6           0.694253    0.518714                          \n",
      "\u001b[J187.596       0           6           0.694253    0.518714                          \n",
      "\u001b[J213.623       0           7           0.67972     0.616805                          \n",
      "\u001b[J213.746       0           7           0.67972     0.616805                          \n",
      "\u001b[J253.864       0           8           0.66646     0.627628                          \n",
      "\u001b[J254.121       0           8           0.66646     0.627628                          \n",
      "\u001b[J288.627       0           9           0.696352    0.495552                          \n",
      "\u001b[J288.74        0           9           0.696352    0.495552                          \n",
      "\u001b[J320.857       0           10          0.696024    0.546367                          \n",
      "\u001b[J321.059       0           10          0.696024    0.546367                          \n",
      "\u001b[J354.858       0           11          0.68949     0.566256                          \n",
      "\u001b[J355.039       0           11          0.68949     0.566256                          \n",
      "\u001b[J384.94        0           12          0.677982    0.55479                           \n",
      "\u001b[J385.11        0           12          0.677982    0.55479                           \n",
      "\u001b[J416.002       0           13          0.679694    0.618763                          \n",
      "\u001b[J416.173       0           13          0.679694    0.618763                          \n",
      "\u001b[J444.217       0           14          0.682339    0.565751                          \n",
      "\u001b[J444.453       0           14          0.682339    0.565751                          \n",
      "\u001b[J478.247       0           15          0.682735    0.558561                          \n",
      "\u001b[J478.449       0           15          0.682735    0.558561                          \n",
      "\u001b[J511.154       0           16          0.678224    0.613476                          \n",
      "\u001b[J511.293       0           16          0.678224    0.613476                          \n",
      "\u001b[J542.513       0           17          0.693898    0.533357                          \n",
      "\u001b[J542.683       0           17          0.693898    0.533357                          \n",
      "\u001b[J573.907       0           18          0.665053    0.615176                          \n",
      "\u001b[J574.066       0           18          0.665053    0.615176                          \n",
      "\u001b[J607.341       0           19          0.680968    0.568279                          \n",
      "\u001b[J607.515       0           19          0.680968    0.568279                          \n",
      "\u001b[J639.296       0           20          0.684505    0.580959                          \n",
      "\u001b[J639.465       0           20          0.684505    0.580959                          \n",
      "\u001b[J665.788       0           21          0.679897    0.523149                          \n",
      "\u001b[J665.973       0           21          0.679897    0.523149                          \n",
      "\u001b[J697.28        0           22          0.693082    0.616606                          \n",
      "\u001b[J697.47        0           22          0.693082    0.616606                          \n",
      "\u001b[J730.077       0           23          0.684439    0.692593                          \n",
      "\u001b[J730.304       0           23          0.684439    0.692593                          \n",
      "\u001b[J766.383       0           24          0.679021    0.662886                          \n",
      "\u001b[J766.599       0           24          0.679021    0.662886                          \n",
      "\u001b[J805.856       0           25          0.680049    0.529697                          \n",
      "\u001b[J806.06        0           25          0.680049    0.529697                          \n",
      "\u001b[J840.577       0           26          0.681732    0.520604                          \n",
      "\u001b[J840.797       0           26          0.681732    0.520604                          \n",
      "\u001b[J873.901       0           27          0.682391    0.655551                          \n",
      "\u001b[J874.18        0           27          0.682391    0.655551                          \n",
      "\u001b[J903.881       0           28          0.683175    0.513736                          \n",
      "\u001b[J904.353       0           28          0.683175    0.513736                          \n",
      "\u001b[J939.222       0           29          0.680993    0.541649                          \n",
      "\u001b[J939.475       0           29          0.680993    0.541649                          \n",
      "\u001b[J972.667       0           30          0.69422     0.674529                          \n",
      "\u001b[J972.945       0           30          0.69422     0.674529                          \n",
      "\u001b[J1004.65       0           31          0.682299    0.622109                          \n",
      "\u001b[J1004.89       0           31          0.682299    0.622109                          \n",
      "\u001b[J1025.26       0           32          0.682595    0.567741                          \n",
      "\u001b[J1025.5        0           32          0.682595    0.567741                          \n",
      "\u001b[J1055.66       0           33          0.683126    0.544967                          \n",
      "\u001b[J1055.95       0           33          0.683126    0.544967                          \n",
      "\u001b[J1084.27       0           34          0.684426    0.671626                          \n",
      "\u001b[J1084.55       0           34          0.684426    0.671626                          \n",
      "\u001b[J1119.3        0           35          0.687059    0.503095                          \n",
      "\u001b[J1119.67       0           35          0.687059    0.503095                          \n",
      "\u001b[J1157.96       0           36          0.68526     0.539726                          \n",
      "\u001b[J1158.23       0           36          0.68526     0.539726                          \n",
      "\u001b[J1288.9        1           37          0.684656    0.445693    0.406905              \n",
      "\u001b[J1289.24       1           37          0.684656    0.445693    0.406905              \n",
      "\u001b[J1327.21       1           38          0.696467    0.438985                          \n",
      "\u001b[J1327.51       1           38          0.696467    0.438985                          \n",
      "\u001b[J1358.82       1           39          0.684852    0.502814                          \n",
      "\u001b[J1359.26       1           39          0.684852    0.502814                          \n",
      "\u001b[J1396.31       1           40          0.686838    0.43021                           \n",
      "\u001b[J1397.38       1           40          0.686838    0.43021                           \n",
      "\u001b[J1426.36       1           41          0.689299    0.423281                          \n",
      "\u001b[J1427.32       1           41          0.689299    0.423281                          \n",
      "\u001b[J1476.17       1           42          0.687964    0.399071                          \n",
      "\u001b[J1477.06       1           42          0.687964    0.399071                          \n",
      "\u001b[J1523.81       1           43          0.687846    0.405368                          \n",
      "\u001b[J1524.76       1           43          0.687846    0.405368                          \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-489ef1704328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnn_setup_base_config.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'101693'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer_monitor/run_experiment.pyc\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(config, mongo_password)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                     \u001b[0;31m'\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mh3\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mExperiment\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0mhas\u001b[0m \u001b[0msetup\u001b[0m \u001b[0msuccessfully\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mstarting\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mh3\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0mn\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0mn\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m Here is the configuration:\\n\\n<pre>{}</pre>'.format(results_dir, pprint.pformat(full_config)))\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# finish up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/training/trainer.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mreporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                     \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/training/updater.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/training/updater.pyc\u001b[0m in \u001b[0;36mupdate_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer_monitor/retain_grad.pyc\u001b[0m in \u001b[0;36mupdate_retain_grad\u001b[0;34m(self, lossfun, *args, **kwds)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlossfun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0muse_cleargrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_use_cleargrads'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_cleargrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleargrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/Development/projects/fbnyc/FoodborneNYC/jamia_2017/revision/experiments/weighted_loss_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, xs, ys, weights, is_biased)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_biased\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0my_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0my_pred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_change_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/Development/projects/fbnyc/FoodborneNYC/jamia_2017/revision/experiments/cnn_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# print 'x_vec shape:', x_vecs.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         filter_activations = [ self.f(conv(F.expand_dims(x_vecs,1)))\n\u001b[0;32m---> 38\u001b[0;31m                                for conv in self.convs ]\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_activations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mmonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f(cnn(activation)) for ngram {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/links/connection/convolution_2d.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         return convolution_2d.convolution_2d(\n\u001b[0;32m--> 154\u001b[0;31m             x, self.W, self.b, self.stride, self.pad)\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/functions/connection/convolution_2d.pyc\u001b[0m in \u001b[0;36mconvolution_2d\u001b[0;34m(x, W, b, stride, pad, cover_all, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/function.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_indexes_to_retain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_indexes_to_retain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitervalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/function.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/functions/connection/convolution_2d.pyc\u001b[0m in \u001b[0;36mforward_cpu\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         self.col = conv.im2col_cpu(\n\u001b[1;32m     86\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             cover_all=self.cover_all)\n\u001b[0m\u001b[1;32m     88\u001b[0m         y = numpy.tensordot(\n\u001b[1;32m     89\u001b[0m             self.col, W, ((1, 2, 3), (1, 2, 3))).astype(x.dtype, copy=False)\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/utils/conv.pyc\u001b[0m in \u001b[0;36mim2col_cpu\u001b[0;34m(img, kh, kw, sy, sx, ph, pw, pval, cover_all, dy, dx)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mi_lim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mout_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mcol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjdy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj_lim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_lim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = yaml.load(open('cnn_setup_base_config.yaml'))\n",
    "run_experiment(config, '101693')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mJun-28-2017-16.30.932571_experiment\u001b[m\u001b[m/ \u001b[34mJun-28-2017-17.06.014814_experiment\u001b[m\u001b[m/\r\n",
      "\u001b[34mJun-28-2017-16.32.101715_experiment\u001b[m\u001b[m/ \u001b[34mJun-28-2017-17.10.327646_experiment\u001b[m\u001b[m/\r\n",
      "\u001b[34mJun-28-2017-16.33.062379_experiment\u001b[m\u001b[m/ \u001b[34mJun-28-2017-17.11.400609_experiment\u001b[m\u001b[m/\r\n",
      "\u001b[34mJun-28-2017-16.46.364098_experiment\u001b[m\u001b[m/ \u001b[34mJun-28-2017-17.15.762166_experiment\u001b[m\u001b[m/\r\n",
      "\u001b[34mJun-28-2017-16.55.304516_experiment\u001b[m\u001b[m/ \u001b[34mJun-28-2017-17.16.971732_experiment\u001b[m\u001b[m/\r\n",
      "\u001b[34mJun-28-2017-16.56.319239_experiment\u001b[m\u001b[m/ \u001b[34mJun-28-2017-18.03.377179_experiment\u001b[m\u001b[m/\r\n",
      "\u001b[34mJun-28-2017-17.01.517068_experiment\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls chainer_experiments/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function chainer.functions.activation.softmax.softmax>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chainer import functions as F\n",
    "F.softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recursive_set_with_slice(base, grid, i):\n",
    "    for gkey in grid:\n",
    "        if type(base[gkey]) is dict:\n",
    "            base[gkey] = recursive_set_with_slice(base[gkey], grid[gkey], i)\n",
    "        else:\n",
    "            base[gkey] = grid[gkey][i]\n",
    "    return base\n",
    "\n",
    "def chainer_random_search(base_config, trials_config, N):\n",
    "    title = base_config['title'][:]\n",
    "    for i in range(N):\n",
    "        config = recursive_set_with_slice(base_config, trials_config, i)\n",
    "        config['title'] = title+' hp[{}]'.format(i)\n",
    "        print 'Experiment {} config: {}'.format(i, config)\n",
    "        run_experiment(config, '101693')\n",
    "    print \"All Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy.random as npr\n",
    "import numpy as np\n",
    "from chainer_monitor.run_experiment import run_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2017-07-01 06:56:05,510: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git commit -a -m \"auto commit tracked files for new experiment: chainer_experiments/Jul-01-2017-06.56.450596_experiment\" --allow-empty'>: starting process\n",
      "[INFO] 2017-07-01 06:56:05,531: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git commit -a -m \"auto commit tracked files for new experiment: chainer_experiments/Jul-01-2017-06.56.450596_experiment\" --allow-empty', pid 96861>: process started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 0 config: {'task': 'DOHMH: Yelp Multiple', 'random_seed': 0, 'description': 'Uses an ngram convolution over the input doc', 'title': 'TEST: CNN simple hp search test hp[0]', 'mongo_config': {'username': 'tom', 'host': 'teffland.cs.columbia.edu', 'port': 27017, 'database': 'experiments'}, 'model_setup': {'setup_file': 'cnn_model_setup.py', 'setup_config': {'cnn_pooling': 'max', 'cnn_activation_func': 'leaky_relu', 'cnn_n_filters_per': 14, 'cnn_ngrams': [1, 2], 'dropout_prob': 0.1824396046889703}}, 'trainer_setup': {'setup_file': 'chainer_trainer_setup.py', 'setup_config': {'adam_alpha': 0.004014230329259693, 'n_epoch': 50, 'early_stop_patience': 5, 'batch_size': 256, 'evaluation_trigger': [1, 'epoch'], 'l2_coef': 0.033472541511564903, 'freeze_embeddings': True, 'max_examples': 1000, 'checkpoint_trigger': [1, 'epoch']}}, 'data_setup': {'setup_file': 'chainer_data_setup.py', 'setup_config': {'lowercase': True, 'pretrained_vectors': '../data/word_vectors/trimmed_glove.840B.300d.txt', 'train_regime': 'biased', 'normalize_vectors': True, 'trim_vector_file': False, 'dev_portion': 0.2, 'split_random_seed': 0, 'response_key': 'is_multiple'}}, 'results_dir_prefix': 'chainer_experiments/', 'email': 'teffland@cs.columbia.edu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2017-07-01 06:56:06,205: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git commit -a -m \"auto commit tracked files for new experiment: chainer_experiments/Jul-01-2017-06.56.450596_experiment\" --allow-empty', pid 96861>: process completed\n",
      "[INFO] 2017-07-01 06:56:06,210: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD'>: starting process\n",
      "[INFO] 2017-07-01 06:56:06,231: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 96865>: process started\n",
      "[INFO] 2017-07-01 06:56:06,240: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 96865>: process completed\n",
      "[INFO] 2017-07-01 06:56:06,241: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 96865>: process completed\n",
      "[INFO] 2017-07-01 06:56:06,243: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 96865>: process completed\n",
      "[INFO] 2017-07-01 06:56:06,250: chainer_monitor.run_experiment: Loading dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pad token to have a zeros embeddings\n",
      "Pretrained coverage: 26372/31173 = 84.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2017-07-01 06:56:43,721: data_setup: 9252 Training examples, 2314 Dev, 2975 Test\n",
      "[INFO] 2017-07-01 06:56:43,778: chainer_monitor.run_experiment: Setting up models\n",
      "[INFO] 2017-07-01 06:56:43,866: chainer_monitor.run_experiment: Setting up training\n",
      "[INFO] 2017-07-01 06:56:43,887: chainer_monitor.run_experiment: Saving experiment configuration\n",
      "[INFO] 2017-07-01 06:56:44,933: chainer_monitor.run_experiment: Running trainer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time  epoch       iteration   main/loss   main/aupr   validation/main/aupr\n",
      "\u001b[J20.5598       0           1           1.0654      0.193112                          \n",
      "\u001b[J21.2858       0           1           1.0654      0.193112                          \n",
      "\u001b[J42.1525       0           2           0.743514    0.107679                          \n",
      "\u001b[J42.2243       0           2           0.743514    0.107679                          \n",
      "\u001b[J60.3224       0           3           0.612688    0.186893                          \n",
      "\u001b[J60.4691       0           3           0.612688    0.186893                          \n",
      "\u001b[J93.5363       1           4           0.567198    0.153035    0.153596              \n",
      "\u001b[J93.6706       1           4           0.567198    0.153035    0.153596              \n",
      "\u001b[J115.629       1           5           0.616826    0.201795                          \n",
      "\u001b[J115.744       1           5           0.616826    0.201795                          \n",
      "\u001b[J135.237       1           6           0.486235    0.160761                          \n",
      "\u001b[J135.325       1           6           0.486235    0.160761                          \n",
      "\u001b[J153.492       1           7           0.509318    0.214244                          \n",
      "\u001b[J154.556       1           7           0.509318    0.214244                          \n",
      "\u001b[J187.984       2           8           0.452272    0.224201    0.162788              \n",
      "\u001b[J188.153       2           8           0.452272    0.224201    0.162788              \n",
      "\u001b[J209.143       2           9           0.427231    0.299651                          \n",
      "\u001b[J209.308       2           9           0.427231    0.299651                          \n",
      "\u001b[J224.813       2           10          0.561775    0.279062                          \n",
      "\u001b[J225.008       2           10          0.561775    0.279062                          \n",
      "\u001b[J243.001       2           11          0.451173    0.259375                          \n",
      "\u001b[J243.149       2           11          0.451173    0.259375                          \n",
      "\u001b[J280.634       3           12          0.401623    0.202516    0.162661              \n",
      "\u001b[J280.791       3           12          0.401623    0.202516    0.162661              \n",
      "\u001b[J300.789       3           13          0.41183     0.188228                          \n",
      "\u001b[J301.001       3           13          0.41183     0.188228                          \n",
      "\u001b[J320.982       3           14          0.399832    0.233805                          \n",
      "\u001b[J321.153       3           14          0.399832    0.233805                          \n",
      "\u001b[J337.517       3           15          0.398832    0.34863                           \n",
      "\u001b[J337.946       3           15          0.398832    0.34863                           \n",
      "\u001b[J373.957       4           16          0.394687    0.414216    0.167506              \n",
      "\u001b[J374.135       4           16          0.394687    0.414216    0.167506              \n",
      "\u001b[J395.479       4           17          0.349874    0.298352                          \n",
      "\u001b[J395.624       4           17          0.349874    0.298352                          \n",
      "\u001b[J413.782       4           18          0.398985    0.437696                          \n",
      "\u001b[J413.931       4           18          0.398985    0.437696                          \n",
      "\u001b[J434.324       4           19          0.411129    0.392935                          \n",
      "\u001b[J434.808       4           19          0.411129    0.392935                          \n",
      "\u001b[J466.569       5           20          0.416022    0.322526    0.179481              \n",
      "\u001b[J466.787       5           20          0.416022    0.322526    0.179481              \n",
      "\u001b[J489.807       5           21          0.349124    0.263378                          \n",
      "\u001b[J490.021       5           21          0.349124    0.263378                          \n",
      "\u001b[J507.376       5           22          0.365119    0.531855                          \n",
      "\u001b[J507.763       5           22          0.365119    0.531855                          \n",
      "\u001b[J527.736       5           23          0.333836    0.24926                           \n",
      "\u001b[J527.977       5           23          0.333836    0.24926                           \n",
      "\u001b[J565.717       6           24          0.410226    0.531308    0.174138              \n",
      "\u001b[J565.976       6           24          0.410226    0.531308    0.174138              \n",
      "\u001b[J585.46        6           25          0.336155    0.429605                          \n",
      "\u001b[J585.688       6           25          0.336155    0.429605                          \n",
      "\u001b[J604.16        6           26          0.328777    0.412013                          \n",
      "\u001b[J604.394       6           26          0.328777    0.412013                          \n",
      "\u001b[J620.982       6           27          0.345519    0.48508                           \n",
      "\u001b[J621.272       6           27          0.345519    0.48508                           \n",
      "\u001b[J658.735       7           28          0.373366    0.53615     0.175826              \n",
      "\u001b[J658.963       7           28          0.373366    0.53615     0.175826              \n",
      "\u001b[J679.239       7           29          0.381695    0.573518                          \n",
      "\u001b[J679.555       7           29          0.381695    0.573518                          \n",
      "\u001b[J698.732       7           30          0.330828    0.386278                          \n",
      "\u001b[J698.957       7           30          0.330828    0.386278                          \n",
      "\u001b[J717.525       7           31          0.303989    0.439258                          \n",
      "\u001b[J717.833       7           31          0.303989    0.439258                          \n",
      "\u001b[J752.092       8           32          0.352658    0.567795    0.174715              \n",
      "\u001b[J752.343       8           32          0.352658    0.567795    0.174715              \n",
      "\u001b[J772.468       8           33          0.334413    0.573325                          \n",
      "\u001b[J772.755       8           33          0.334413    0.573325                          \n",
      "\u001b[J788.849       8           34          0.321947    0.355495                          \n",
      "\u001b[J789.129       8           34          0.321947    0.355495                          \n",
      "\u001b[J807.848       8           35          0.338624    0.513813                          \n",
      "\u001b[J808.128       8           35          0.338624    0.513813                          \n",
      "\u001b[J845.796       9           36          0.305515    0.586325    0.17302               \n",
      "\u001b[J846.149       9           36          0.305515    0.586325    0.17302               \n",
      "\u001b[J861.691       9           37          0.386219    0.519912                          \n",
      "\u001b[J862.03        9           37          0.386219    0.519912                          \n",
      "\u001b[J879.711       9           38          0.290662    0.514731                          \n",
      "\u001b[J880.029       9           38          0.290662    0.514731                          \n",
      "\u001b[J899.05        9           39          0.33984     0.569486                          \n",
      "\u001b[J899.326       9           39          0.33984     0.569486                          \n",
      "\u001b[J935.577       10          40          0.325106    0.396299    0.164491              \n",
      "\u001b[J935.884       10          40          0.325106    0.396299    0.164491              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2017-07-01 07:12:28,329: chainer_monitor.run_experiment: Finished Experiment\n",
      "[INFO] 2017-07-01 07:12:31,791: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git commit -a -m \"auto commit tracked files for new experiment: chainer_experiments/Jul-01-2017-07.12.790160_experiment\" --allow-empty'>: starting process\n",
      "[INFO] 2017-07-01 07:12:31,806: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git commit -a -m \"auto commit tracked files for new experiment: chainer_experiments/Jul-01-2017-07.12.790160_experiment\" --allow-empty', pid 97278>: process started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1 config: {'task': 'DOHMH: Yelp Multiple', 'random_seed': 0, 'description': 'Uses an ngram convolution over the input doc', 'title': 'TEST: CNN simple hp search test hp[1]', 'start_time': datetime.datetime(2017, 7, 1, 6, 56, 43, 888484), 'mongo_config': {'username': 'tom', 'host': 'teffland.cs.columbia.edu', 'port': 27017, 'database': 'experiments'}, 'model_setup': {'setup_file': 'cnn_model_setup.py', 'setup_config': {'cnn_pooling': 'max', 'cnn_activation_func': 'leaky_relu', 'cnn_n_filters_per': 14, 'cnn_ngrams': [1, 2], 'dropout_prob': 0.26237979441018966}}, 'hostname': 'Thomass-MacBook-Pro-2.local', 'pid': 94837, 'total_iterations': 200, 'cwd': '/Users/thomaseffland/Development/projects/fbnyc/FoodborneNYC/jamia_2017/revision/experiments', '_id': ObjectId('59577feb8ca2097276994b40'), 'finish_time': datetime.datetime(2017, 7, 1, 7, 12, 28, 329947), 'trainer_setup': {'setup_file': 'chainer_trainer_setup.py', 'setup_config': {'adam_alpha': 0.007695515694333091, 'n_epoch': 50, 'early_stop_patience': 5, 'experiment_uid': 'Jul-01-2017-06.56.450596', 'results_dirname': 'chainer_experiments/Jul-01-2017-06.56.450596_experiment', 'batch_size': 256, 'evaluation_trigger': [1, 'epoch'], 'l2_coef': 3.3690745980625993, 'mongo_config': {'username': 'tom', 'host': 'teffland.cs.columbia.edu', 'port': 27017, 'database': 'experiments'}, 'freeze_embeddings': True, 'max_examples': 1000, 'checkpoint_trigger': [1, 'epoch']}}, 'commit_hash': u'd6148e116cdb8c3123492c78ca57541fafc833d4', 'data_setup': {'setup_file': 'chainer_data_setup.py', 'setup_config': {'lowercase': True, 'pretrained_vectors': '../data/word_vectors/trimmed_glove.840B.300d.txt', 'train_regime': 'biased', 'normalize_vectors': True, 'trim_vector_file': False, 'dev_portion': 0.2, 'split_random_seed': 0, 'response_key': 'is_multiple'}}, 'results_dir_prefix': 'chainer_experiments/', 'results_dirname': 'chainer_experiments/Jul-01-2017-06.56.450596_experiment', 'email': 'teffland@cs.columbia.edu', 'uid': 'Jul-01-2017-06.56.450596'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2017-07-01 07:12:32,063: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git commit -a -m \"auto commit tracked files for new experiment: chainer_experiments/Jul-01-2017-07.12.790160_experiment\" --allow-empty', pid 97278>: process completed\n",
      "[INFO] 2017-07-01 07:12:32,067: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD'>: starting process\n",
      "[INFO] 2017-07-01 07:12:32,097: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 97281>: process started\n",
      "[INFO] 2017-07-01 07:12:32,107: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 97281>: process completed\n",
      "[INFO] 2017-07-01 07:12:32,108: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 97281>: process completed\n",
      "[INFO] 2017-07-01 07:12:32,110: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 97281>: process completed\n",
      "[INFO] 2017-07-01 07:12:32,117: chainer_monitor.run_experiment: Loading dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pad token to have a zeros embeddings\n",
      "Pretrained coverage: 26372/31173 = 84.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2017-07-01 07:13:08,403: data_setup: 9252 Training examples, 2314 Dev, 2975 Test\n",
      "[INFO] 2017-07-01 07:13:08,463: chainer_monitor.run_experiment: Setting up models\n",
      "[INFO] 2017-07-01 07:13:08,589: chainer_monitor.run_experiment: Setting up training\n",
      "[INFO] 2017-07-01 07:13:08,673: chainer_monitor.run_experiment: Saving experiment configuration\n",
      "[INFO] 2017-07-01 07:13:09,080: chainer_monitor.run_experiment: Running trainer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time  epoch       iteration   main/loss   main/aupr   validation/main/aupr\n",
      "\u001b[J21.3517       0           1           1.32279     0.112468                          \n",
      "\u001b[J22.0859       0           1           1.32279     0.112468                          \n",
      "\u001b[J41.2696       0           2           0.988693    0.173461                          \n",
      "\u001b[J41.3788       0           2           0.988693    0.173461                          \n",
      "\u001b[J59.8112       0           3           0.818645    0.0861435                         \n",
      "\u001b[J60.4416       0           3           0.818645    0.0861435                         \n",
      "\u001b[J97.2545       1           4           0.686155    0.147076    0.146789              \n",
      "\u001b[J97.3688       1           4           0.686155    0.147076    0.146789              \n",
      "\u001b[J118.931       1           5           0.619084    0.156913                          \n",
      "\u001b[J119.055       1           5           0.619084    0.156913                          \n",
      "\u001b[J138.143       1           6           0.582834    0.143571                          \n",
      "\u001b[J138.346       1           6           0.582834    0.143571                          \n",
      "\u001b[J156.882       1           7           0.553       0.166138                          \n",
      "\u001b[J156.979       1           7           0.553       0.166138                          \n",
      "\u001b[J190.763       2           8           0.567784    0.131218    0.133162              \n",
      "\u001b[J190.893       2           8           0.567784    0.131218    0.133162              \n",
      "\u001b[J209.382       2           9           0.547621    0.154842                          \n",
      "\u001b[J209.537       2           9           0.547621    0.154842                          \n",
      "\u001b[J229.25        2           10          0.558349    0.13885                           \n",
      "\u001b[J229.382       2           10          0.558349    0.13885                           \n",
      "\u001b[J247.508       2           11          0.536803    0.17863                           \n",
      "\u001b[J247.841       2           11          0.536803    0.17863                           \n",
      "\u001b[J282.593       3           12          0.54399     0.195766    0.13719               \n",
      "\u001b[J282.717       3           12          0.54399     0.195766    0.13719               \n",
      "\u001b[J301.192       3           13          0.537402    0.141892                          \n",
      "\u001b[J301.3         3           13          0.537402    0.141892                          \n",
      "\u001b[J321.498       3           14          0.557466    0.185924                          \n",
      "\u001b[J321.604       3           14          0.557466    0.185924                          \n",
      "\u001b[J340.003       3           15          0.537265    0.180438                          \n",
      "\u001b[J340.131       3           15          0.537265    0.180438                          \n",
      "\u001b[J380.999       4           16          0.551402    0.195198    0.128837              \n",
      "\u001b[J381.146       4           16          0.551402    0.195198    0.128837              \n",
      "\u001b[J402.823       4           17          0.535617    0.196637                          \n",
      "\u001b[J402.985       4           17          0.535617    0.196637                          \n",
      "\u001b[J421.077       4           18          0.55749     0.122791                          \n",
      "\u001b[J421.5         4           18          0.55749     0.122791                          \n",
      "\u001b[J438.932       4           19          0.55235     0.179052                          \n",
      "\u001b[J439.189       4           19          0.55235     0.179052                          \n",
      "\u001b[J476.52        5           20          0.556095    0.116462    0.130796              \n",
      "\u001b[J476.697       5           20          0.556095    0.116462    0.130796              \n",
      "\u001b[J494.644       5           21          0.559158    0.178869                          \n",
      "\u001b[J494.789       5           21          0.559158    0.178869                          \n",
      "\u001b[J512.714       5           22          0.561491    0.143456                          \n",
      "\u001b[J512.94        5           22          0.561491    0.143456                          \n",
      "\u001b[J532.369       5           23          0.571487    0.186646                          \n",
      "\u001b[J532.556       5           23          0.571487    0.186646                          \n",
      "\u001b[J566.086       6           24          0.565514    0.118351    0.127814              \n",
      "\u001b[J566.245       6           24          0.565514    0.118351    0.127814              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2017-07-01 07:22:40,347: chainer_monitor.run_experiment: Finished Experiment\n",
      "[INFO] 2017-07-01 07:22:43,290: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git commit -a -m \"auto commit tracked files for new experiment: chainer_experiments/Jul-01-2017-07.22.289338_experiment\" --allow-empty'>: starting process\n",
      "[INFO] 2017-07-01 07:22:43,307: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git commit -a -m \"auto commit tracked files for new experiment: chainer_experiments/Jul-01-2017-07.22.289338_experiment\" --allow-empty', pid 97541>: process started\n",
      "[INFO] 2017-07-01 07:22:43,464: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git commit -a -m \"auto commit tracked files for new experiment: chainer_experiments/Jul-01-2017-07.22.289338_experiment\" --allow-empty', pid 97541>: process completed\n",
      "[INFO] 2017-07-01 07:22:43,469: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD'>: starting process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 2 config: {'task': 'DOHMH: Yelp Multiple', 'random_seed': 0, 'description': 'Uses an ngram convolution over the input doc', 'title': 'TEST: CNN simple hp search test hp[2]', 'start_time': datetime.datetime(2017, 7, 1, 7, 13, 8, 675248), 'mongo_config': {'username': 'tom', 'host': 'teffland.cs.columbia.edu', 'port': 27017, 'database': 'experiments'}, 'model_setup': {'setup_file': 'cnn_model_setup.py', 'setup_config': {'cnn_pooling': 'max', 'cnn_activation_func': 'leaky_relu', 'cnn_n_filters_per': 37, 'cnn_ngrams': [1], 'dropout_prob': 0.29807949040169918}}, 'hostname': 'Thomass-MacBook-Pro-2.local', 'pid': 94837, 'total_iterations': 200, 'cwd': '/Users/thomaseffland/Development/projects/fbnyc/FoodborneNYC/jamia_2017/revision/experiments', '_id': ObjectId('595783c48ca2097276994b6b'), 'finish_time': datetime.datetime(2017, 7, 1, 7, 22, 40, 348667), 'trainer_setup': {'setup_file': 'chainer_trainer_setup.py', 'setup_config': {'adam_alpha': 0.0087032948733430579, 'n_epoch': 50, 'early_stop_patience': 5, 'experiment_uid': 'Jul-01-2017-07.12.790160', 'results_dirname': 'chainer_experiments/Jul-01-2017-07.12.790160_experiment', 'batch_size': 256, 'evaluation_trigger': [1, 'epoch'], 'l2_coef': 6.6143074814368763, 'mongo_config': {'username': 'tom', 'host': 'teffland.cs.columbia.edu', 'port': 27017, 'database': 'experiments'}, 'freeze_embeddings': True, 'max_examples': 1000, 'checkpoint_trigger': [1, 'epoch']}}, 'commit_hash': u'adb6e52400731b83ecee03eb556513242d6ec3e0', 'data_setup': {'setup_file': 'chainer_data_setup.py', 'setup_config': {'lowercase': True, 'pretrained_vectors': '../data/word_vectors/trimmed_glove.840B.300d.txt', 'train_regime': 'biased', 'normalize_vectors': True, 'trim_vector_file': False, 'dev_portion': 0.2, 'split_random_seed': 0, 'response_key': 'is_multiple'}}, 'results_dir_prefix': 'chainer_experiments/', 'results_dirname': 'chainer_experiments/Jul-01-2017-07.12.790160_experiment', 'email': 'teffland@cs.columbia.edu', 'uid': 'Jul-01-2017-07.12.790160'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2017-07-01 07:22:43,492: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 97544>: process started\n",
      "[INFO] 2017-07-01 07:22:43,498: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 97544>: process completed\n",
      "[INFO] 2017-07-01 07:22:43,500: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 97544>: process completed\n",
      "[INFO] 2017-07-01 07:22:43,502: sh.command: <Command u'/Applications/Xcode.app/Contents/Developer/usr/bin/git rev-parse HEAD', pid 97544>: process completed\n",
      "[INFO] 2017-07-01 07:22:43,509: chainer_monitor.run_experiment: Loading dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pad token to have a zeros embeddings\n",
      "Pretrained coverage: 26372/31173 = 84.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2017-07-01 07:23:18,764: data_setup: 9252 Training examples, 2314 Dev, 2975 Test\n",
      "[INFO] 2017-07-01 07:23:18,816: chainer_monitor.run_experiment: Setting up models\n",
      "[INFO] 2017-07-01 07:23:18,918: chainer_monitor.run_experiment: Setting up training\n",
      "[INFO] 2017-07-01 07:23:18,940: chainer_monitor.run_experiment: Saving experiment configuration\n",
      "[INFO] 2017-07-01 07:23:19,116: chainer_monitor.run_experiment: Running trainer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time  epoch       iteration   main/loss   main/aupr   validation/main/aupr\n",
      "\u001b[J12.2911       0           1           0.508926    0.144912                          \n",
      "\u001b[J12.5764       0           1           0.508926    0.144912                          \n",
      "\u001b[J25.1675       0           2           0.46163     0.147169                          \n",
      "\u001b[J25.2239       0           2           0.46163     0.147169                          \n",
      "\u001b[J35.8692       0           3           0.503992    0.185899                          \n",
      "\u001b[J35.9443       0           3           0.503992    0.185899                          \n",
      "\u001b[J54.5845       1           4           0.515379    0.139948    0.134108              \n",
      "\u001b[J54.6866       1           4           0.515379    0.139948    0.134108              \n",
      "\u001b[J71.6206       1           5           0.516611    0.1579                            \n",
      "\u001b[J71.6996       1           5           0.516611    0.1579                            \n",
      "\u001b[J83.3188       1           6           0.524571    0.168467                          \n",
      "\u001b[J83.3876       1           6           0.524571    0.168467                          \n",
      "\u001b[J94.7587       1           7           0.498539    0.125851                          \n",
      "\u001b[J94.8562       1           7           0.498539    0.125851                          \n",
      "\u001b[J114.793       2           8           0.524393    0.112925    0.139639              \n",
      "\u001b[J114.864       2           8           0.524393    0.112925    0.139639              \n",
      "\u001b[J131.159       2           9           0.520426    0.155309                          \n",
      "\u001b[J131.238       2           9           0.520426    0.155309                          \n",
      "\u001b[J143.581       2           10          0.514245    0.115699                          \n",
      "\u001b[J143.704       2           10          0.514245    0.115699                          \n",
      "\u001b[J155.335       2           11          0.554894    0.136828                          \n",
      "\u001b[J155.454       2           11          0.554894    0.136828                          \n",
      "\u001b[J172.947       3           12          0.559332    0.166683    0.125294              \n",
      "\u001b[J173.055       3           12          0.559332    0.166683    0.125294              \n",
      "\u001b[J186.551       3           13          0.53946     0.127444                          \n",
      "\u001b[J186.643       3           13          0.53946     0.127444                          \n",
      "\u001b[J198.971       3           14          0.5759      0.151026                          \n",
      "\u001b[J199.088       3           14          0.5759      0.151026                          \n",
      "\u001b[J210.619       3           15          0.570426    0.138268                          \n",
      "\u001b[J210.717       3           15          0.570426    0.138268                          \n",
      "\u001b[J231.744       4           16          0.573315    0.236936    0.157079              \n",
      "\u001b[J231.979       4           16          0.573315    0.236936    0.157079              \n",
      "\u001b[J250.611       4           17          0.577439    0.118672                          \n",
      "\u001b[J250.734       4           17          0.577439    0.118672                          \n",
      "\u001b[J261.532       4           18          0.576135    0.124255                          \n",
      "\u001b[J261.651       4           18          0.576135    0.124255                          \n",
      "\u001b[J273.8         4           19          0.595135    0.172342                          \n",
      "\u001b[J273.915       4           19          0.595135    0.172342                          \n",
      "\u001b[J293.958       5           20          0.598348    0.12395     0.131137              \n",
      "\u001b[J294.127       5           20          0.598348    0.12395     0.131137              \n",
      "\u001b[J306.54        5           21          0.593657    0.136484                          \n",
      "\u001b[J306.664       5           21          0.593657    0.136484                          \n",
      "\u001b[J318.866       5           22          0.613506    0.177751                          \n",
      "\u001b[J318.995       5           22          0.613506    0.177751                          \n",
      "\u001b[J331.026       5           23          0.606278    0.135821                          \n",
      "\u001b[J333.209       5           23          0.606278    0.135821                          \n",
      "\u001b[J354.365       6           24          0.615113    0.120379    0.105486              \n",
      "\u001b[J354.609       6           24          0.615113    0.120379    0.105486              \n",
      "\u001b[J370.872       6           25          0.623437    0.139725                          \n",
      "\u001b[J371.014       6           25          0.623437    0.139725                          \n",
      "\u001b[J381.98        6           26          0.625054    0.123768                          \n",
      "\u001b[J382.124       6           26          0.625054    0.123768                          \n",
      "\u001b[J394.084       6           27          0.628918    0.128156                          \n",
      "\u001b[J394.242       6           27          0.628918    0.128156                          \n",
      "\u001b[J416.707       7           28          0.634587    0.11598     0.156248              \n",
      "\u001b[J416.868       7           28          0.634587    0.11598     0.156248              \n",
      "\u001b[J433.703       7           29          0.637204    0.112944                          \n",
      "\u001b[J433.879       7           29          0.637204    0.112944                          \n",
      "\u001b[J446.302       7           30          0.644816    0.118178                          \n",
      "\u001b[J446.51        7           30          0.644816    0.118178                          \n",
      "\u001b[J459.026       7           31          0.644127    0.113687                          \n",
      "\u001b[J459.209       7           31          0.644127    0.113687                          \n",
      "\u001b[J478.057       8           32          0.641479    0.0779738   0.083703              \n",
      "\u001b[J478.254       8           32          0.641479    0.0779738   0.083703              \n",
      "\u001b[J495.437       8           33          0.652801    0.126423                          \n",
      "\u001b[J495.725       8           33          0.652801    0.126423                          \n",
      "\u001b[J510.014       8           34          0.645755    0.0815221                         \n",
      "\u001b[J510.359       8           34          0.645755    0.0815221                         \n",
      "\u001b[J526.341       8           35          0.649426    0.0892291                         \n",
      "\u001b[J526.519       8           35          0.649426    0.0892291                         \n",
      "\u001b[J545.904       9           36          0.650882    0.088019    0.070382              \n",
      "\u001b[J546.114       9           36          0.650882    0.088019    0.070382              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2017-07-01 07:32:29,484: chainer_monitor.run_experiment: Finished Experiment\n"
     ]
    }
   ],
   "source": [
    "base = yaml.load(open('cnn_setup_simple_test_config.yaml'))\n",
    "N = 3\n",
    "base['title'] = \"TEST: \"+base['title']\n",
    "random_points = {\n",
    "    'model_setup':{\n",
    "        'setup_config':{\n",
    "            'cnn_ngrams':[range(1,n) for n in npr.choice([2,3,4], N)],\n",
    "            'cnn_n_filters_per':npr.randint(10,50, N),\n",
    "            'dropout_prob':npr.uniform(.1,.4, N)\n",
    "        }\n",
    "    },\n",
    "    'trainer_setup':{\n",
    "        'setup_config': {\n",
    "            'adam_alpha':npr.uniform(1e-3, 1e-2, N),\n",
    "            'l2_coef':[10.**e for e in npr.uniform(-3,1, N)]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "chainer_random_search(base, random_points, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0000001e-19"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float32(1e-18 - 1e-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
