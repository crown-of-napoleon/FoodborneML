{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection Bias Correction\n",
    "\n",
    "Let $T(x)$ be the biased black-box selection process for labelling data at DOHMH.\n",
    "\n",
    "Let $U$ be the set of all Yelp Reviews that have been processed by the system.\n",
    "\n",
    "Let $B \\subset U$ s.t. $B = \\{(x,y) | T(x) = 1\\}$ and $B^c \\subseteq U \\setminus B$\n",
    "\n",
    "### Training: Error Rate\n",
    "\n",
    "We can model the error rate of some classifier $f$ as:\n",
    "\n",
    "$p(f(x) \\neq y) = \\Sigma_{t}{p( f(x) \\neq y | T(x) = t)p(T(x)=t)}$\n",
    "\n",
    "and use plugin estimates:\n",
    "\n",
    "$\\hat{p}(T(x) = 1) = \\frac{|B|}{|U|}$ (the % of labeled points)\n",
    "\n",
    "$\\hat{p}(f(x) \\neq y | T(x)=1) = \\frac{1}{|B|}\\Sigma_{(x,y) \\in B}{I[f(x) \\neq y]}$\n",
    "\n",
    "likewise,\n",
    "\n",
    "$\\hat{p}(f(x) \\neq y | T(x)=0) = \\frac{1}{|B^c|}\\Sigma_{(x,y) \\in B^c}{I[f(x) \\neq y]}$\n",
    "\n",
    "therefore\n",
    "\n",
    "$\\hat{p}(f(x) \\neq y) = w_B\\Sigma_{(x,y) \\in B}{I[f(x) \\neq y]} + w_{B^c}\\Sigma_{(x,y) \\in B^c}{I[f(x) \\neq y]}$\n",
    "\n",
    "where \n",
    "\n",
    "$w_B = \\frac{1}{|U|}$ and $w_{B^c} = (1 - \\frac{|B|}{|U|})(\\frac{1}{|B^c|})$\n",
    "\n",
    "Note that when $B^c$ is the entire complement of $B$, then $w_{B^c}$ reduces to $\\frac{1}{|U|}$\n",
    "\n",
    "So, if we are trying to minimize the classification error in the objective function (which cross entropy does) then these are the sample weights to be used when calculating the error\n",
    "\n",
    "### Testing: Area Under Precision-Recall Curve\n",
    "\n",
    "We will evaluate models using the AUPR metric, calculated empirically on the dev and test sets.\n",
    "\n",
    "This metric is appropriate because of the major positive-class imbalance in the dataset (estimated to be.7%).\n",
    "\n",
    "The tricky thing is that our measures of precision and recall need to also be importance weighted, and the importance weights for precision will vary as we vary the threshold.\n",
    "\n",
    "To see why, consider the probabilistic form of precision for some classifier $f$:\n",
    "\n",
    "#### Precision\n",
    "\n",
    "Let $U$ be the test set.\n",
    "\n",
    "$Precision = p(y=1|f(x)=1) = \\Sigma_{t}{p(y=1 | f(x)=1, T(x) = t)p(T(x)=t|f(x)=1)}$\n",
    "\n",
    "Let $U_P \\subset U$ be the set $\\{(x,y) | f(x) = 1\\}$. \n",
    "\n",
    "**Note** that $U_P$ varies with the classification threshold.\n",
    "\n",
    "Then as with the error rate, we can find plugin estimates for the necessary quanities.\n",
    "\n",
    "$\\hat{p}(T(x) = 1|f(x)=1) = \\frac{1}{|U_P|} \\Sigma_{(x,y) \\in B}{I[f(x)=1]} = \\frac{|B \\cap U_P|}{|U_P|}$\n",
    "\n",
    "and so $\\hat{p}(T(x) = 0|f(x)=1) = 1 - \\frac{|B \\cap U_P|}{|U_P|}$\n",
    "\n",
    "Also,\n",
    "\n",
    "$\\hat{p}(y=1|f(x)=1, T(x)=1) = \\frac{1}{|U_P|} \\Sigma_{(x,y) \\in B\\cap U_P}{I[y=1]} \n",
    " $\n",
    "\n",
    "and $\\hat{p}(y=1|f(x)=1, T(x)=0) = \\frac{1}{|U_P|} \\Sigma_{(x,y) \\in B^c\\cap U_P}{I[y=1]}$\n",
    "\n",
    "Therefore\n",
    "\n",
    "$Precision = \\frac{|B \\cap U_P|}{|U_P|} \\frac{1}{|U_P|} \\Sigma_{(x,y) \\in B\\cap U_P}{I[y=1]} \n",
    "+ (1 - \\frac{|B \\cap U_P|}{|U_P|})\\frac{1}{|U_P|} \\Sigma_{(x,y) \\in B^c\\cap U_P}{I[y=1]}$\n",
    "\n",
    "#### Recall\n",
    "\n",
    "The derivation for improtance-weighted (IW) recall follows similary to IW precision.\n",
    "\n",
    "$Recall = p(f(x)=1|y=1) = \\Sigma_{t}{p(f(x)=1| y=1, T(x) = t)p(T(x)=t|y=1)}$\n",
    "\n",
    "Let $U_R \\subset U$ be the set $\\{(x,y) | y = 1\\}$. \n",
    "\n",
    "**Note** that $U_R$ **does not** vary with the classification threshold.\n",
    "\n",
    "The plugin estimates are:\n",
    "\n",
    "$\\hat{p}(T(x) = 1|y=1) = \\frac{1}{|U_R|} \\Sigma_{(x,y) \\in B}{I[y=1]} = \\frac{|B \\cap U_R|}{|U_R|}$\n",
    "\n",
    "and so $\\hat{p}(T(x) = 0|y=1) = 1 - \\frac{|B \\cap U_R|}{|U_R|}$\n",
    "\n",
    "Also,\n",
    "\n",
    "$\\hat{p}(f(x)=1 |y=1, T(x)=1) = \\frac{1}{|U_R|} \\Sigma_{(x,y) \\in B\\cap U_R}{I[f(x)=1]}$\n",
    "\n",
    "and $\\hat{p}(f(x)=1|y=1, T(x)=0) = \\frac{1}{|U_R|} \\Sigma_{(x,y) \\in B^c\\cap U_R}{I[f(x)=1]}$\n",
    "\n",
    "plugging in we have\n",
    "\n",
    "$ Recall =  \\frac{|B \\cap U_R|}{|U_R|} \\frac{1}{|U_R|} \\Sigma_{(x,y) \\in B\\cap U_R}{I[f(x)=1]}\n",
    "+ (1 - \\frac{|B \\cap U_R|}{|U_R|}) \\frac{1}{|U_R|} \\Sigma_{(x,y) \\in B^c\\cap U_R}{I[f(x)=1]}$\n",
    "\n",
    "#### AUPR Curve\n",
    "\n",
    "Finally, using the above plugin estimates, we can balance data from both $B$ and (a sample from) $B^c$.  We can obtain a series of ordered Precision-Recall points $E = \\{(p,r,t)_i | r_i \\leq r_{i'}\\}$ by varying the classification threshold $t \\in [0,1]$ and then using trapezoidal integration to approximate the area under the Recall vs. Precision curve.\n",
    "\n",
    "#### Bootstrap\n",
    "\n",
    "For the final evaluation, we would like confidence intervals about the AUPR. We find these by using the percentile bootstrap:\n",
    "\n",
    "We calculate bootstrap statistics for the IW-AUPR as follows:\n",
    "\n",
    "First we calculate the test data IW-AUPR. Call this $\\bar{x}$.\n",
    "\n",
    "Then we resample the test dataset with replacement $B$ times and obtain the IW-AUPR estimates for each set.\n",
    "\n",
    "Call these $x_1, ...,  x_B$.\n",
    "\n",
    "Then we can compute confidence intervals around $\\bar{x}$ the usual way by finding the $\\alpha=.025$ boundary quantiles $\\delta_{\\alpha}, \\delta_{1-\\alpha}$, such that \n",
    "\n",
    "$$P(\\bar{x}^* - \\delta_{1-\\alpha} \\leq \\bar{x} \\leq \\bar{x}^* - \\delta_{\\alpha}) = .95$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* [X] Take the historical unbiased data and check if any of it is in the biased data. Replace all that are.\n",
    "* [X] Setup datasets from the two training regimes\n",
    "* [X] Preprocess datasets for the baselines (scikit models)\n",
    "* [X] Code up IW objective function for baselines\n",
    "* [X] Quick test training of baselines\n",
    "* [X] Code up the dev AUPR evaluation metric.\n",
    "* [X] Batch out 100 random search cross-validated hyperparam experiments for the RF, SVM, and LR baselines\n",
    "* [X] Implement the CNN\n",
    "* [X] Batch out 100 random search early-stopping hyperparam experiments for CNN\n",
    "* [X] Finish up the viz for chainer monitor\n",
    "* [ ] Implement the DyCNN\n",
    "* [ ] Redraft paper\n",
    "* [ ] Get official test results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Official Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import itertools\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "sb.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from experiments.baseline_experiment_util import calc_train_importance_weights\n",
    "from experiments.baseline_experiment_util import importance_weighted_precision_recall, importance_weighted_pr_curve\n",
    "from experiments.baseline_experiment_util import setup_baseline_data, area_under_pr_curve\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from experiments.lr_model import model as lr_model\n",
    "from experiments.rf_model import model as rf_model\n",
    "from experiments.svm_model import model as svm_model\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiments/baseline_experiment_util.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  old_biased['is_foodborne'] = old_biased['is_foodborne'].map({'Yes':1, 'No':0})\n",
      "experiments/baseline_experiment_util.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  new_biased['is_foodborne'] = new_biased['is_foodborne'].map({'Yes':1, 'No':0})\n",
      "experiments/baseline_experiment_util.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  old_biased['is_multiple'] = old_biased['is_multiple'].map({'Yes':1, 'No':0})\n",
      "experiments/baseline_experiment_util.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  new_biased['is_multiple'] = new_biased['is_multiple'].map({'Yes':1, 'No':0})\n"
     ]
    }
   ],
   "source": [
    "biased_data = setup_baseline_data(data_path='data', train_regime='biased', test_regime='gold', random_seed=0)\n",
    "gold_data = setup_baseline_data(data_path='data', train_regime='gold', test_regime='gold', random_seed=0)\n",
    "silver_data = setup_baseline_data(data_path='data', train_regime='silver', test_regime='gold', random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train setup\n",
    "biased_text = np.array(biased_data['train_data']['text'])\n",
    "biased_sick = np.array(biased_data['train_data']['is_foodborne'])\n",
    "biased_mult = np.array(biased_data['train_data']['is_multiple'])\n",
    "biased_weights = calc_train_importance_weights(biased_data['train_data']['is_biased'], biased_data['U'])\n",
    "\n",
    "gold_text = np.array(gold_data['train_data']['text'])\n",
    "gold_sick = np.array(gold_data['train_data']['is_foodborne'])\n",
    "gold_mult = np.array(gold_data['train_data']['is_multiple'])\n",
    "gold_weights = calc_train_importance_weights(gold_data['train_data']['is_biased'], gold_data['U'])\n",
    "\n",
    "silver_text = np.array(silver_data['train_data']['text'])\n",
    "silver_sick = np.array(silver_data['train_data']['is_foodborne'])\n",
    "silver_mult = np.array(silver_data['train_data']['is_multiple'])\n",
    "silver_weights = calc_train_importance_weights(silver_data['train_data']['is_biased'], silver_data['U'])\n",
    "\n",
    "# test setup\n",
    "test_data = gold_data['test_data']\n",
    "B = 1000 # number of bootstrap test set resamples\n",
    "random_seed = 0\n",
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f1(precision, recall):\n",
    "    return 2.*precision*recall/(precision+recall+1e-15)\n",
    "\n",
    "def iw_bootstrap_score_ci(trues, preds, is_biased, scoring_func, \n",
    "                          B=1000, confidence_level=.99, \n",
    "                          random_seed=None,\n",
    "                          **scoring_func_kwds):\n",
    "    \"\"\" Compute a bootstrapped estimate of the importance weighted model score and stratified resampling.\n",
    "    \n",
    "    An intuitive and practical guide to bootstrap estimation:\n",
    "    https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading24.pdf\n",
    "    \"\"\"\n",
    "    if random_seed: npr.seed(random_seed)\n",
    "    xbar = scoring_func(trues, preds, is_biased, **scoring_func_kwds)\n",
    "    samples = []\n",
    "    biased_idxs = np.argwhere(is_biased).ravel()\n",
    "    nonbiased_idxs = np.argwhere(~is_biased).ravel()\n",
    "    print\n",
    "    for i in range(B):\n",
    "        print '\\rB: {}/{}'.format(i,B),\n",
    "        if len(nonbiased_idxs):\n",
    "            sample = np.hstack([npr.choice(biased_idxs, len(biased_idxs)), \n",
    "                                npr.choice(nonbiased_idxs, len(nonbiased_idxs))])\n",
    "        else:\n",
    "            sample = npr.choice(biased_idxs, len(biased_idxs))\n",
    "        samples.append(scoring_func(trues[sample], preds[sample], is_biased[sample], **scoring_func_kwds))\n",
    "    diffs = [ xbar - xi for xi in samples]\n",
    "    alpha = (1. - confidence_level)/2.\n",
    "    ci_bottom = xbar - np.percentile(diffs, 100.*(1-alpha))\n",
    "    ci_top = xbar - np.percentile(diffs, 100.*alpha)\n",
    "    return xbar, ci_bottom, ci_top, samples\n",
    "\n",
    "def bootstrap_f1_ci(trues, preds, is_biased, random_seed=None, **bootstrap_kwds):\n",
    "    def scorer(trues, preds, is_biased):\n",
    "        p, r = importance_weighted_precision_recall(trues, preds, is_biased, threshold=.5)\n",
    "        return f1(p,r)\n",
    "    return iw_bootstrap_score_ci(trues, preds, is_biased, scorer,\n",
    "                              random_seed=random_seed,\n",
    "                              **bootstrap_kwds)\n",
    "\n",
    "def bootstrap_aupr_ci(trues, preds, is_biased, random_seed=None, **bootstrap_kwds):\n",
    "    def scorer(trues, preds, is_biased):\n",
    "        ps, rs, ts = importance_weighted_pr_curve(trues, preds, is_biased, n_thresholds=50)\n",
    "        return area_under_pr_curve(ps, rs)\n",
    "    return iw_bootstrap_score_ci(trues, preds, is_biased, scorer,\n",
    "                              random_seed=random_seed,\n",
    "                              **bootstrap_kwds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def subplot_confusion_matrix(cm, classes, \n",
    "                             fig, ax,\n",
    "                             precision=None, recall=None, f1_ci=None,\n",
    "                             normalize=False,\n",
    "                             title='Confusion matrix',\n",
    "                             cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \n",
    "    Modified from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "    \"\"\"\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.set_title(title)\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        ax.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    ax.set_ylabel('True label')\n",
    "    xlabel = 'Predicted label'\n",
    "    if (precision is not None) and (recall is not None):\n",
    "        xlabel += '\\nPrecision: {0:2.3f}, Recall: {1:2.3f}'.format(precision, recall)\n",
    "    if f1_ci is not None:\n",
    "        xlabel +='\\nF1: {0:2.3f}, CI:({1:2.3f}, {2:2.3f})'.format(*f1_ci)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.grid(False)\n",
    "\n",
    "def model_report(model, title, label_key, save_fname=None, test_data=test_data, **bootstrap_kwds):\n",
    "    y_trues = np.array(test_data[label_key])\n",
    "    is_biased = np.array(test_data['is_biased'])\n",
    "    y_preds = model.predict(test_data['text'])\n",
    "    y_pred_probs = model.predict_proba(test_data['text'])[:,1]\n",
    "    ps, rs, ts = importance_weighted_pr_curve(y_trues, y_pred_probs, is_biased)\n",
    "    aupr, aupr_ci_bottom, aupr_ci_top, samples = bootstrap_aupr_ci(y_trues, y_pred_probs, is_biased, **bootstrap_kwds)\n",
    "#     print '--- {} ---'.format(title)\n",
    "#     print '  Precision@.5, Recall@.5: {0:2.2f}, {1:2.2f}'.format(precision, recall)\n",
    "#     print '  AUPR: {0:2.2f}'.format(aupr)\n",
    "    fig, axs = plt.subplots(2,2, figsize=(8,8))\n",
    "    axs[0,0].plot(rs, ps, label='AUPR: {0:2.3f} CI=({1:2.3f}, {2:2.3f})'.format(aupr, aupr_ci_bottom, aupr_ci_top))\n",
    "    axs[0,0].set_title('Precision Recall Curve')\n",
    "    axs[0,0].set_xlabel('Recall')\n",
    "    axs[0,0].set_ylabel('Precision')\n",
    "    axs[0,0].legend(loc=8)\n",
    "    \n",
    "    # plot out cms for mixed, biased, and nonbiased\n",
    "    precision_m, recall_m = importance_weighted_precision_recall(y_trues, y_pred_probs, is_biased, .5)\n",
    "    f1_ci_m = bootstrap_f1_ci(y_trues, y_pred_probs, is_biased, **bootstrap_kwds)\n",
    "    cm = confusion_matrix(y_trues, y_preds)\n",
    "    subplot_confusion_matrix(cm, ['Not Sick', 'Sick'], fig, axs[0,1], \n",
    "                             title='Mixed Bias',\n",
    "                             precision=precision_m, recall=recall_m, f1_ci=f1_ci_m[:3])\n",
    "    # biased\n",
    "    precision_b, recall_b = importance_weighted_precision_recall(y_trues[is_biased], \n",
    "                                                             y_pred_probs[is_biased], \n",
    "                                                             is_biased[is_biased], .5)\n",
    "    f1_ci_b = bootstrap_f1_ci(y_trues[is_biased], y_pred_probs[is_biased], is_biased[is_biased], **bootstrap_kwds)\n",
    "    cm = confusion_matrix(y_trues[is_biased], y_preds[is_biased])\n",
    "    subplot_confusion_matrix(cm, ['Not Sick', 'Sick'], fig, axs[1,0], \n",
    "                             title='Biased',\n",
    "                             precision=precision_b, recall=recall_b, f1_ci=f1_ci_b[:3])\n",
    "    # nonbiased\n",
    "    # there is no point to reporting precision, recall here since there are no positives\n",
    "    # but we do it anyways in case the dataset were to change\n",
    "    precision, recall = importance_weighted_precision_recall(y_trues[~is_biased], \n",
    "                                                             y_pred_probs[~is_biased], \n",
    "                                                             is_biased[~is_biased], .5)\n",
    "#     f1_ci = bootstrap_f1_ci(y_trues[~is_biased], y_pred_probs[~is_biased], is_biased[~is_biased], **bootstrap_kwds)\n",
    "    cm = confusion_matrix(y_trues[~is_biased], y_preds[~is_biased])\n",
    "    subplot_confusion_matrix(cm, ['Not Sick', 'Sick'], fig, axs[1,1], \n",
    "                             title=\"Nonbiased (all No's)\",\n",
    "                             precision=precision, recall=recall)\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig.suptitle(title + ' Test Report', fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.92)\n",
    "    if save_fname:\n",
    "        plt.savefig(save_fname+'_report.pdf')\n",
    "    \n",
    "    # also plot the bootstrap historgrams to make sure they look ok\n",
    "    fig2, axs2 = plt.subplots(1,3, figsize=(12,4))\n",
    "    axs2[0].hist(samples, bins=100)\n",
    "    axs2[0].axvline(aupr, color='red')\n",
    "    axs2[0].axvspan(aupr_ci_bottom, aupr_ci_top, alpha=.25, color='red')\n",
    "    axs2[0].set_title('AUPR Bootstrap')\n",
    "    axs2[1].hist(f1_ci_m[3], bins=100)\n",
    "    axs2[1].axvline(f1_ci_m[0], color='red')\n",
    "    axs2[1].axvspan(f1_ci_m[1], f1_ci_m[2], alpha=.25, color='red')\n",
    "    axs2[1].set_title('Mixed Bias F1 Boostrap')\n",
    "    axs2[2].hist(f1_ci_b[3], bins=100)\n",
    "    axs2[2].axvline(f1_ci_b[0], color='red')\n",
    "    axs2[2].axvspan(f1_ci_b[1], f1_ci_b[2], alpha=.25, color='red')\n",
    "    axs2[2].set_title('Biased F1 Boostrap')\n",
    "    fig2.suptitle(title + ' Bootstrap Histograms', fontsize=14)\n",
    "    fig2.tight_layout()\n",
    "    fig2.subplots_adjust(top=0.85)\n",
    "    if save_fname:\n",
    "        plt.savefig(save_fname+'_bootstrap_hists.pdf')\n",
    "        \n",
    "    return {\n",
    "        'aupr':aupr,\n",
    "        'aupr_ci':(aupr_ci_bottom, aupr_ci_top),\n",
    "        'aupr_samples':samples,\n",
    "        'mixed_precision':precision_m,\n",
    "        'mixed_recall':recall_m,\n",
    "        'mixed_f1':f1_ci_m[0],\n",
    "        'mixed_f1_ci':f1_ci_m[1:3],\n",
    "        'mixed_f1_samples':f1_ci_m[3],\n",
    "        'biased_precision':precision_b,\n",
    "        'biased_recall':recall_b,\n",
    "        'biased_f1':f1_ci_b[0],\n",
    "        'biased_f1_ci':f1_ci_b[1:3],\n",
    "        'biased_f1_samples':f1_ci_b[3]\n",
    "    }\n",
    "        \n",
    "def print_model_hyperparams(model, name):\n",
    "    useful_params = {k:v for k,v in model.get_params().items() if '__' in k}\n",
    "    print \"*** {} Hyperparameters ***\".format(name)\n",
    "    pprint(useful_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sick Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the notable stats for testing on the Sick task:\n",
    "* All the test data is from 1/1/2017 and later\n",
    "* It's about 2/3 biased and 1/3 nonbiased (1975 and 1000 reviews, respectively)\n",
    "* All 1000 nonbiased reviews are have `No` labels\n",
    "* The 1975 biased reviews are about 52% `Yes`/`No` (1026/949)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2026\n",
       "1     949\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(test_data['is_foodborne']).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1975\n",
       "False    1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(test_data['is_biased']).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.18.1 when using version 0.18.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.18.1 when using version 0.18.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.18.1 when using version 0.18.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator Pipeline from version 0.18.1 when using version 0.18.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "best_sick_lr_biased = joblib.load('experiments/best_models/best_lr_sick_biased.pkl')\n",
    "best_sick_lr_gold = joblib.load('experiments/best_models/best_lr_sick_gold.pkl')\n",
    "best_sick_lr_silver = joblib.load('experiments/best_models/best_lr_sick_silver.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.92876195959267271, max_features=None,\n",
       "        min_df=1, ngram_range=(1, 3), preprocessor=None, stop_words...ty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sick_lr_biased.fit(biased_text, biased_sick, logreg__sample_weight=biased_weights)\n",
    "best_sick_lr_gold.fit(gold_text, gold_sick, logreg__sample_weight=gold_weights)\n",
    "best_sick_lr_silver.fit(silver_text, silver_sick, logreg__sample_weight=silver_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "B: 139/1000"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "title = 'Logistic Regression Sick Biased'\n",
    "all_results[title] = model_report(best_sick_lr_biased, title, 'is_foodborne',\n",
    "                                  save_fname='figures/sick_lr_biased',\n",
    "                                  B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'Logistic Regression Sick Gold'\n",
    "all_results[title] = model_report(best_sick_lr_gold, title, 'is_foodborne', \n",
    "                                   save_fname='figures/sick_lr_gold',\n",
    "                                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'Logistic Regression Sick Silver'\n",
    "all_results[title] = model_report(best_sick_lr_silver, title, 'is_foodborne', \n",
    "                       save_fname='figures/sick_lr_silver',\n",
    "                       B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Logistic Regression Sick Biased Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.84528542746895707,\n",
      " 'count__max_features': None,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 3),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'logreg__C': 1.0043849350273031,\n",
      " 'logreg__class_weight': None,\n",
      " 'logreg__dual': False,\n",
      " 'logreg__fit_intercept': True,\n",
      " 'logreg__intercept_scaling': 1,\n",
      " 'logreg__max_iter': 100,\n",
      " 'logreg__multi_class': 'ovr',\n",
      " 'logreg__n_jobs': 1,\n",
      " 'logreg__penalty': 'l2',\n",
      " 'logreg__random_state': None,\n",
      " 'logreg__solver': 'liblinear',\n",
      " 'logreg__tol': 0.0001,\n",
      " 'logreg__verbose': 0,\n",
      " 'logreg__warm_start': False,\n",
      " 'tfidf__norm': 'l2',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': True}\n",
      "\n",
      "*** Logistic Regression Sick Gold Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.90323583246016548,\n",
      " 'count__max_features': None,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 3),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'logreg__C': 363.62695199335934,\n",
      " 'logreg__class_weight': None,\n",
      " 'logreg__dual': False,\n",
      " 'logreg__fit_intercept': True,\n",
      " 'logreg__intercept_scaling': 1,\n",
      " 'logreg__max_iter': 100,\n",
      " 'logreg__multi_class': 'ovr',\n",
      " 'logreg__n_jobs': 1,\n",
      " 'logreg__penalty': 'l1',\n",
      " 'logreg__random_state': None,\n",
      " 'logreg__solver': 'liblinear',\n",
      " 'logreg__tol': 0.0001,\n",
      " 'logreg__verbose': 0,\n",
      " 'logreg__warm_start': False,\n",
      " 'tfidf__norm': 'l2',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': True}\n",
      "\n",
      "*** Logistic Regression Sick Silver Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.92876195959267271,\n",
      " 'count__max_features': None,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 3),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'logreg__C': 9.7498716797727401,\n",
      " 'logreg__class_weight': None,\n",
      " 'logreg__dual': False,\n",
      " 'logreg__fit_intercept': True,\n",
      " 'logreg__intercept_scaling': 1,\n",
      " 'logreg__max_iter': 100,\n",
      " 'logreg__multi_class': 'ovr',\n",
      " 'logreg__n_jobs': 1,\n",
      " 'logreg__penalty': 'l2',\n",
      " 'logreg__random_state': None,\n",
      " 'logreg__solver': 'liblinear',\n",
      " 'logreg__tol': 0.0001,\n",
      " 'logreg__verbose': 0,\n",
      " 'logreg__warm_start': False,\n",
      " 'tfidf__norm': None,\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': False}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_hyperparams(best_sick_lr_biased, 'Logistic Regression Sick Biased')\n",
    "print\n",
    "print_model_hyperparams(best_sick_lr_gold, 'Logistic Regression Sick Gold')\n",
    "print\n",
    "print_model_hyperparams(best_sick_lr_silver, 'Logistic Regression Sick Silver')\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.18 when using version 0.18.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.18 when using version 0.18.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.18 when using version 0.18.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.18 when using version 0.18.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator Pipeline from version 0.18 when using version 0.18.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "best_sick_rf_biased = joblib.load('experiments/best_models/best_rf_sick_biased.pkl')\n",
    "best_sick_rf_gold = joblib.load('experiments/best_models/best_rf_sick_gold.pkl')\n",
    "best_sick_rf_silver = joblib.load('experiments/best_models/best_rf_sick_silver.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.79926139280934727, max_features=1000,\n",
       "        min_df=1, ngram_range=(1, 3), preprocessor=None, stop_words...estimators=134, n_jobs=4, oob_score=True, random_state=0,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sick_rf_biased.fit(biased_text, biased_sick, rf__sample_weight=biased_weights)\n",
    "best_sick_rf_gold.fit(gold_text, gold_sick, rf__sample_weight=gold_weights)\n",
    "best_sick_rf_silver.fit(silver_text, silver_sick, rf__sample_weight=silver_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'Random Forest Sick Biased'\n",
    "all_results[title] = model_report(best_sick_rf_biased, title, 'is_foodborne',\n",
    "                                   save_fname='figures/sick_rf_biased',\n",
    "                                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'Random Forest Sick Gold'\n",
    "all_results[title] = model_report(best_sick_rf_gold, title, 'is_foodborne',\n",
    "                                   save_fname='figures/sick_rf_gold',\n",
    "                                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'Random Forest Sick Silver'\n",
    "all_results[title] = model_report(best_sick_rf_silver, title, 'is_foodborne',\n",
    "                   save_fname='figures/sick_rf_silver',\n",
    "                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Random Forest Sick Biased Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.86314175655936753,\n",
      " 'count__max_features': 1000,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 2),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'rf__bootstrap': True,\n",
      " 'rf__class_weight': None,\n",
      " 'rf__criterion': 'gini',\n",
      " 'rf__max_depth': None,\n",
      " 'rf__max_features': 'sqrt',\n",
      " 'rf__max_leaf_nodes': None,\n",
      " 'rf__min_impurity_split': 1e-07,\n",
      " 'rf__min_samples_leaf': 1,\n",
      " 'rf__min_samples_split': 2,\n",
      " 'rf__min_weight_fraction_leaf': 0.0,\n",
      " 'rf__n_estimators': 192,\n",
      " 'rf__n_jobs': 4,\n",
      " 'rf__oob_score': True,\n",
      " 'rf__random_state': 0,\n",
      " 'rf__verbose': 0,\n",
      " 'rf__warm_start': False,\n",
      " 'tfidf__norm': 'l1',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': True}\n",
      "\n",
      "*** Random Forest Sick Gold Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.9368966695653862,\n",
      " 'count__max_features': 1000,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 2),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'rf__bootstrap': True,\n",
      " 'rf__class_weight': None,\n",
      " 'rf__criterion': 'gini',\n",
      " 'rf__max_depth': None,\n",
      " 'rf__max_features': 'sqrt',\n",
      " 'rf__max_leaf_nodes': None,\n",
      " 'rf__min_impurity_split': 1e-07,\n",
      " 'rf__min_samples_leaf': 1,\n",
      " 'rf__min_samples_split': 2,\n",
      " 'rf__min_weight_fraction_leaf': 0.0,\n",
      " 'rf__n_estimators': 156,\n",
      " 'rf__n_jobs': 1,\n",
      " 'rf__oob_score': True,\n",
      " 'rf__random_state': 0,\n",
      " 'rf__verbose': 0,\n",
      " 'rf__warm_start': False,\n",
      " 'tfidf__norm': 'l1',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': True}\n",
      "\n",
      "*** Random Forest Sick Silver Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.79926139280934727,\n",
      " 'count__max_features': 1000,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 3),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'rf__bootstrap': True,\n",
      " 'rf__class_weight': None,\n",
      " 'rf__criterion': 'gini',\n",
      " 'rf__max_depth': None,\n",
      " 'rf__max_features': 'sqrt',\n",
      " 'rf__max_leaf_nodes': None,\n",
      " 'rf__min_impurity_split': 1e-07,\n",
      " 'rf__min_samples_leaf': 1,\n",
      " 'rf__min_samples_split': 2,\n",
      " 'rf__min_weight_fraction_leaf': 0.0,\n",
      " 'rf__n_estimators': 134,\n",
      " 'rf__n_jobs': 4,\n",
      " 'rf__oob_score': True,\n",
      " 'rf__random_state': 0,\n",
      " 'rf__verbose': 0,\n",
      " 'rf__warm_start': False,\n",
      " 'tfidf__norm': 'l2',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': False}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_hyperparams(best_sick_rf_biased, 'Random Forest Sick Biased')\n",
    "print\n",
    "print_model_hyperparams(best_sick_rf_gold, 'Random Forest Sick Gold')\n",
    "print\n",
    "print_model_hyperparams(best_sick_rf_silver, 'Random Forest Sick Silver')\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_sick_svm_biased = joblib.load('experiments/best_models/best_svm_sick_biased.pkl')\n",
    "best_sick_svm_gold = joblib.load('experiments/best_models/best_svm_sick_gold.pkl')\n",
    "best_sick_svm_silver = joblib.load('experiments/best_models/best_svm_sick_silver.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.86862870075359322, max_features=None,\n",
       "        min_df=1, ngram_range=(1, 2), preprocessor=None, stop_words...',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sick_svm_biased.fit(biased_text, biased_sick, svc__sample_weight=biased_weights)\n",
    "best_sick_svm_gold.fit(gold_text, gold_sick, svc__sample_weight=gold_weights)\n",
    "best_sick_svm_silver.fit(silver_text, silver_sick, svc__sample_weight=silver_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'SVM Sick Biased'\n",
    "all_results[title] = model_report(best_sick_svm_biased, title, 'is_foodborne',\n",
    "                   save_fname='figures/sick_svm_biased',\n",
    "                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'SVM Sick Gold'\n",
    "all_results[title] = model_report(best_sick_svm_gold, title, 'is_foodborne',\n",
    "                   save_fname='figures/sick_svm_gold',\n",
    "                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'SVM Sick Silver'\n",
    "all_results[title] = model_report(best_sick_svm_silver, title, 'is_foodborne',\n",
    "                   save_fname='figures/sick_svm_silver',\n",
    "                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SVM Sick Biased Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.81119879980332688,\n",
      " 'count__max_features': None,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 2),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'svc__C': 1.0712799833880016,\n",
      " 'svc__cache_size': 200,\n",
      " 'svc__class_weight': None,\n",
      " 'svc__coef0': 0.0,\n",
      " 'svc__decision_function_shape': None,\n",
      " 'svc__degree': 3,\n",
      " 'svc__gamma': 'auto',\n",
      " 'svc__kernel': 'linear',\n",
      " 'svc__max_iter': -1,\n",
      " 'svc__probability': True,\n",
      " 'svc__random_state': None,\n",
      " 'svc__shrinking': True,\n",
      " 'svc__tol': 0.001,\n",
      " 'svc__verbose': False,\n",
      " 'tfidf__norm': None,\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': True}\n",
      "\n",
      "*** SVM Sick Gold Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.81066358134332872,\n",
      " 'count__max_features': None,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 3),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'svc__C': 0.86038626608788882,\n",
      " 'svc__cache_size': 200,\n",
      " 'svc__class_weight': None,\n",
      " 'svc__coef0': 0.0,\n",
      " 'svc__decision_function_shape': None,\n",
      " 'svc__degree': 3,\n",
      " 'svc__gamma': 'auto',\n",
      " 'svc__kernel': 'linear',\n",
      " 'svc__max_iter': -1,\n",
      " 'svc__probability': True,\n",
      " 'svc__random_state': None,\n",
      " 'svc__shrinking': True,\n",
      " 'svc__tol': 0.001,\n",
      " 'svc__verbose': False,\n",
      " 'tfidf__norm': None,\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': True}\n",
      "\n",
      "*** SVM Sick Silver Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.86862870075359322,\n",
      " 'count__max_features': None,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 2),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'svc__C': 2.7067194537909298,\n",
      " 'svc__cache_size': 200,\n",
      " 'svc__class_weight': None,\n",
      " 'svc__coef0': 0.0,\n",
      " 'svc__decision_function_shape': None,\n",
      " 'svc__degree': 3,\n",
      " 'svc__gamma': 'auto',\n",
      " 'svc__kernel': 'rbf',\n",
      " 'svc__max_iter': -1,\n",
      " 'svc__probability': True,\n",
      " 'svc__random_state': None,\n",
      " 'svc__shrinking': True,\n",
      " 'svc__tol': 0.001,\n",
      " 'svc__verbose': False,\n",
      " 'tfidf__norm': 'l2',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': False}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_hyperparams(best_sick_svm_biased, 'SVM Sick Biased')\n",
    "print\n",
    "print_model_hyperparams(best_sick_svm_gold, 'SVM Sick Gold')\n",
    "print\n",
    "print_model_hyperparams(best_sick_svm_silver, 'SVM Sick Silver')\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the notable stats for testing on the Multple task:\n",
    "* All the test data is from 1/1/2017 and later\n",
    "* It's about 2/3 biased and 1/3 nonbiased (1975 and 1000 reviews, respectively)\n",
    "* All 1000 nonbiased reviews all have `No` labels\n",
    "* The 1975 biased reviews are about 14% `Yes` (277 `Yes`, 1698 `No`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2698\n",
       "1     277\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(test_data['is_multiple']).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_mult_lr_biased = joblib.load('experiments/best_models/best_lr_mult_biased.pkl')\n",
    "best_mult_lr_gold = joblib.load('experiments/best_models/best_lr_mult_gold.pkl')\n",
    "best_mult_lr_silver = joblib.load('experiments/best_models/best_lr_mult_silver.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.8181949574949251, max_features=None,\n",
       "        min_df=1, ngram_range=(1, 2), preprocessor=None, stop_words=...ty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mult_lr_biased.fit(biased_text, biased_mult, logreg__sample_weight=biased_weights)\n",
    "best_mult_lr_gold.fit(gold_text, gold_mult, logreg__sample_weight=gold_weights)\n",
    "best_mult_lr_silver.fit(silver_text, silver_mult, logreg__sample_weight=silver_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'Logistic Regression Mult Biased'\n",
    "all_results[title] = model_report(best_mult_lr_biased, title, 'is_multiple',\n",
    "                   save_fname='figures/mult_lr_biased',\n",
    "                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'Logistic Regression Mult Gold'\n",
    "all_results[title] = model_report(best_mult_lr_gold, title, 'is_multiple',\n",
    "                   save_fname='figures/mult_lr_gold',\n",
    "                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'Logistic Regression Mult Silver'\n",
    "all_results[title] = model_report(best_mult_lr_silver, title, 'is_multiple',\n",
    "                   save_fname='figures/mult_lr_silver',\n",
    "                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Logistic Regression Mult Biased Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.89510489382036751,\n",
      " 'count__max_features': None,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 3),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'logreg__C': 16.866411904124611,\n",
      " 'logreg__class_weight': None,\n",
      " 'logreg__dual': False,\n",
      " 'logreg__fit_intercept': True,\n",
      " 'logreg__intercept_scaling': 1,\n",
      " 'logreg__max_iter': 100,\n",
      " 'logreg__multi_class': 'ovr',\n",
      " 'logreg__n_jobs': 1,\n",
      " 'logreg__penalty': 'l2',\n",
      " 'logreg__random_state': None,\n",
      " 'logreg__solver': 'liblinear',\n",
      " 'logreg__tol': 0.0001,\n",
      " 'logreg__verbose': 0,\n",
      " 'logreg__warm_start': False,\n",
      " 'tfidf__norm': 'l2',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': True}\n",
      "\n",
      "*** Logistic Regression Mult Gold Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.81993982636775786,\n",
      " 'count__max_features': None,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 2),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'logreg__C': 4409.2470847914083,\n",
      " 'logreg__class_weight': None,\n",
      " 'logreg__dual': False,\n",
      " 'logreg__fit_intercept': True,\n",
      " 'logreg__intercept_scaling': 1,\n",
      " 'logreg__max_iter': 100,\n",
      " 'logreg__multi_class': 'ovr',\n",
      " 'logreg__n_jobs': 1,\n",
      " 'logreg__penalty': 'l2',\n",
      " 'logreg__random_state': None,\n",
      " 'logreg__solver': 'liblinear',\n",
      " 'logreg__tol': 0.0001,\n",
      " 'logreg__verbose': 0,\n",
      " 'logreg__warm_start': False,\n",
      " 'tfidf__norm': 'l2',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': True}\n",
      "\n",
      "*** Logistic Regression Mult Silver Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.8181949574949251,\n",
      " 'count__max_features': None,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 2),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'logreg__C': 8663.5077728261076,\n",
      " 'logreg__class_weight': None,\n",
      " 'logreg__dual': False,\n",
      " 'logreg__fit_intercept': True,\n",
      " 'logreg__intercept_scaling': 1,\n",
      " 'logreg__max_iter': 100,\n",
      " 'logreg__multi_class': 'ovr',\n",
      " 'logreg__n_jobs': 1,\n",
      " 'logreg__penalty': 'l2',\n",
      " 'logreg__random_state': None,\n",
      " 'logreg__solver': 'liblinear',\n",
      " 'logreg__tol': 0.0001,\n",
      " 'logreg__verbose': 0,\n",
      " 'logreg__warm_start': False,\n",
      " 'tfidf__norm': 'l2',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_hyperparams(best_mult_lr_biased, 'Logistic Regression Mult Biased')\n",
    "print\n",
    "print_model_hyperparams(best_mult_lr_gold, 'Logistic Regression Mult Gold')\n",
    "print\n",
    "print_model_hyperparams(best_mult_lr_silver, 'Logistic Regression Mult Silver')\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_mult_rf_biased = joblib.load('experiments/best_models/best_rf_mult_biased.pkl')\n",
    "best_mult_rf_gold = joblib.load('experiments/best_models/best_rf_mult_gold.pkl')\n",
    "best_mult_rf_silver = joblib.load('experiments/best_models/best_rf_mult_silver.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.80352618636857176, max_features=1000,\n",
       "        min_df=1, ngram_range=(1, 2), preprocessor=None, stop_words...estimators=194, n_jobs=4, oob_score=True, random_state=0,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mult_rf_biased.fit(biased_text, biased_mult, rf__sample_weight=biased_weights)\n",
    "best_mult_rf_gold.fit(gold_text, gold_mult, rf__sample_weight=gold_weights)\n",
    "best_mult_rf_silver.fit(silver_text, silver_mult, rf__sample_weight=silver_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'Random Forest Mult Biased'\n",
    "all_results[title] = model_report(best_mult_rf_biased, title, 'is_multiple',\n",
    "                   save_fname='figures/mult_rf_biased',\n",
    "                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'Random Forest Mult Gold'\n",
    "all_results[title] = model_report(best_mult_rf_gold, title, 'is_multiple',\n",
    "                   save_fname='figures/mult_rf_gold',\n",
    "                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'Random Forest Mult Silver'\n",
    "all_results[title] = model_report(best_mult_rf_silver, title, 'is_multiple',\n",
    "                   save_fname='figures/mult_rf_silver',\n",
    "                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Random Forest Mult Biased Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.91095818181620702,\n",
      " 'count__max_features': 1000,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 2),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'rf__bootstrap': True,\n",
      " 'rf__class_weight': None,\n",
      " 'rf__criterion': 'gini',\n",
      " 'rf__max_depth': None,\n",
      " 'rf__max_features': 'sqrt',\n",
      " 'rf__max_leaf_nodes': None,\n",
      " 'rf__min_impurity_split': 1e-07,\n",
      " 'rf__min_samples_leaf': 1,\n",
      " 'rf__min_samples_split': 2,\n",
      " 'rf__min_weight_fraction_leaf': 0.0,\n",
      " 'rf__n_estimators': 167,\n",
      " 'rf__n_jobs': 4,\n",
      " 'rf__oob_score': True,\n",
      " 'rf__random_state': 0,\n",
      " 'rf__verbose': 0,\n",
      " 'rf__warm_start': False,\n",
      " 'tfidf__norm': 'l2',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': False}\n",
      "\n",
      "*** Random Forest Mult Gold Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.91249377022223643,\n",
      " 'count__max_features': 1000,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 2),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'rf__bootstrap': True,\n",
      " 'rf__class_weight': None,\n",
      " 'rf__criterion': 'gini',\n",
      " 'rf__max_depth': None,\n",
      " 'rf__max_features': 'sqrt',\n",
      " 'rf__max_leaf_nodes': None,\n",
      " 'rf__min_impurity_split': 1e-07,\n",
      " 'rf__min_samples_leaf': 1,\n",
      " 'rf__min_samples_split': 2,\n",
      " 'rf__min_weight_fraction_leaf': 0.0,\n",
      " 'rf__n_estimators': 186,\n",
      " 'rf__n_jobs': 4,\n",
      " 'rf__oob_score': True,\n",
      " 'rf__random_state': 0,\n",
      " 'rf__verbose': 0,\n",
      " 'rf__warm_start': False,\n",
      " 'tfidf__norm': 'l2',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': False}\n",
      "\n",
      "*** Random Forest Mult Silver Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.80352618636857176,\n",
      " 'count__max_features': 1000,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 2),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'rf__bootstrap': True,\n",
      " 'rf__class_weight': None,\n",
      " 'rf__criterion': 'gini',\n",
      " 'rf__max_depth': None,\n",
      " 'rf__max_features': 'sqrt',\n",
      " 'rf__max_leaf_nodes': None,\n",
      " 'rf__min_impurity_split': 1e-07,\n",
      " 'rf__min_samples_leaf': 1,\n",
      " 'rf__min_samples_split': 2,\n",
      " 'rf__min_weight_fraction_leaf': 0.0,\n",
      " 'rf__n_estimators': 194,\n",
      " 'rf__n_jobs': 4,\n",
      " 'rf__oob_score': True,\n",
      " 'rf__random_state': 0,\n",
      " 'rf__verbose': 0,\n",
      " 'rf__warm_start': False,\n",
      " 'tfidf__norm': 'l2',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': False}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_hyperparams(best_mult_rf_biased, 'Random Forest Mult Biased')\n",
    "print\n",
    "print_model_hyperparams(best_mult_rf_gold, 'Random Forest Mult Gold')\n",
    "print\n",
    "print_model_hyperparams(best_mult_rf_silver, 'Random Forest Mult Silver')\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_mult_svm_biased = joblib.load('experiments/best_models/best_svm_mult_biased.pkl')\n",
    "best_mult_svm_gold = joblib.load('experiments/best_models/best_svm_mult_gold.pkl')\n",
    "best_mult_svm_silver = joblib.load('experiments/best_models/best_svm_mult_silver.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.84144420079219573, max_features=None,\n",
       "        min_df=1, ngram_range=(1, 2), preprocessor=None, stop_words...',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mult_svm_biased.fit(biased_text, biased_mult, svc__sample_weight=biased_weights)\n",
    "best_mult_svm_gold.fit(gold_text, gold_mult, svc__sample_weight=gold_weights)\n",
    "best_mult_svm_silver.fit(silver_text, silver_mult, svc__sample_weight=silver_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'SVM Mult Biased'\n",
    "all_results[title] = model_report(best_mult_svm_biased, title, 'is_multiple',\n",
    "                   save_fname='figures/mult_svm_biased',\n",
    "                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'SVM Mult Gold'\n",
    "all_results[title] = model_report(best_mult_svm_gold, title, 'is_multiple',\n",
    "                   save_fname='figures/mult_svm_gold',\n",
    "                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "title = 'SVM Mult Silver'\n",
    "all_results[title] = model_report(best_mult_svm_silver, title, 'is_multiple',\n",
    "                   save_fname='figures/mult_svm_silver',\n",
    "                   B=B, random_seed=random_seed)\n",
    "print '{} seconds'.format(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SVM Mult Biased Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.77321625014344464,\n",
      " 'count__max_features': None,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 2),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'svc__C': 0.55052123745597503,\n",
      " 'svc__cache_size': 200,\n",
      " 'svc__class_weight': None,\n",
      " 'svc__coef0': 0.0,\n",
      " 'svc__decision_function_shape': None,\n",
      " 'svc__degree': 3,\n",
      " 'svc__gamma': 'auto',\n",
      " 'svc__kernel': 'rbf',\n",
      " 'svc__max_iter': -1,\n",
      " 'svc__probability': True,\n",
      " 'svc__random_state': None,\n",
      " 'svc__shrinking': True,\n",
      " 'svc__tol': 0.001,\n",
      " 'svc__verbose': False,\n",
      " 'tfidf__norm': 'l2',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': True}\n",
      "\n",
      "*** SVM Mult Gold Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.86994897636290802,\n",
      " 'count__max_features': None,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 2),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'svc__C': 389.0980066345877,\n",
      " 'svc__cache_size': 200,\n",
      " 'svc__class_weight': None,\n",
      " 'svc__coef0': 0.0,\n",
      " 'svc__decision_function_shape': None,\n",
      " 'svc__degree': 3,\n",
      " 'svc__gamma': 'auto',\n",
      " 'svc__kernel': 'linear',\n",
      " 'svc__max_iter': -1,\n",
      " 'svc__probability': True,\n",
      " 'svc__random_state': None,\n",
      " 'svc__shrinking': True,\n",
      " 'svc__tol': 0.001,\n",
      " 'svc__verbose': False,\n",
      " 'tfidf__norm': 'l2',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': False}\n",
      "\n",
      "*** SVM Mult Silver Hyperparameters ***\n",
      "{'count__analyzer': u'word',\n",
      " 'count__binary': False,\n",
      " 'count__decode_error': u'strict',\n",
      " 'count__dtype': <type 'numpy.int64'>,\n",
      " 'count__encoding': u'utf-8',\n",
      " 'count__input': u'content',\n",
      " 'count__lowercase': True,\n",
      " 'count__max_df': 0.84144420079219573,\n",
      " 'count__max_features': None,\n",
      " 'count__min_df': 1,\n",
      " 'count__ngram_range': (1, 2),\n",
      " 'count__preprocessor': None,\n",
      " 'count__stop_words': None,\n",
      " 'count__strip_accents': None,\n",
      " 'count__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " 'count__tokenizer': None,\n",
      " 'count__vocabulary': None,\n",
      " 'svc__C': 699.65588015657761,\n",
      " 'svc__cache_size': 200,\n",
      " 'svc__class_weight': None,\n",
      " 'svc__coef0': 0.0,\n",
      " 'svc__decision_function_shape': None,\n",
      " 'svc__degree': 3,\n",
      " 'svc__gamma': 'auto',\n",
      " 'svc__kernel': 'rbf',\n",
      " 'svc__max_iter': -1,\n",
      " 'svc__probability': True,\n",
      " 'svc__random_state': None,\n",
      " 'svc__shrinking': True,\n",
      " 'svc__tol': 0.001,\n",
      " 'svc__verbose': False,\n",
      " 'tfidf__norm': 'l2',\n",
      " 'tfidf__smooth_idf': True,\n",
      " 'tfidf__sublinear_tf': False,\n",
      " 'tfidf__use_idf': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_hyperparams(best_mult_svm_biased, 'SVM Mult Biased')\n",
    "print\n",
    "print_model_hyperparams(best_mult_svm_gold, 'SVM Mult Gold')\n",
    "print\n",
    "print_model_hyperparams(best_mult_svm_silver, 'SVM Mult Silver')\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sick_table = pd.DataFrame()\n",
    "mult_table = pd.DataFrame()\n",
    "for name, result in sorted(all_results.items(), key=lambda x:x[0]):\n",
    "    data = {k:v for k,v in result.items() if ('samples' not in k) and ('ci' not in k) }\n",
    "    data.update({k+'_b':v[0] for k,v in result.items() if '_ci' in k})\n",
    "    data.update({k+'_t':v[1] for k,v in result.items() if '_ci' in k})\n",
    "    data['name'] = name\n",
    "    if 'Sick' in name:\n",
    "        sick_table = sick_table.append(data, ignore_index=True)\n",
    "    else:\n",
    "        mult_table = mult_table.append(data, ignore_index=True)\n",
    "sick_table.set_index('name', inplace=True)\n",
    "mult_table.set_index('name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sick_table.to_csv('baseline_sick_results.csv')\n",
    "sick_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mult_table.to_csv('baseline_mult_results.csv')\n",
    "mult_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_sick_model = best_sick_lr_silver\n",
    "best_mult_model = best_mult_lr_biased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis\n",
    "\n",
    "We analyze error for the best models:\n",
    "* Sick: Logistic Regression Silver\n",
    "* Multiple: Logistic Regression Mult Biased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297  to analyze\n"
     ]
    }
   ],
   "source": [
    "y_trues = np.array(test_data['is_foodborne'])\n",
    "preds = best_sick_model.predict_proba(test_data['text'])[:,1]\n",
    "sick_errors = (preds > .5) != y_trues\n",
    "\n",
    "sick_error_df = pd.DataFrame({\n",
    "        'text':np.array(test_data['text'])[sick_errors],\n",
    "        'y_true':y_trues[sick_errors],\n",
    "        'prob':preds[sick_errors],\n",
    "        'is_biased':np.array(test_data['is_biased'])[sick_errors]\n",
    "    })\n",
    "sick_error_df['error_type'] = \"\"\n",
    "sick_error_df['comments'] = \"\"\n",
    "print len(sick_error_df), ' to analyze'\n",
    "sick_error_df = sick_error_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "sick_error_df.to_excel('sick_errors_to_analyze.xlsx', encoding=\"utf8\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182  to analyze\n"
     ]
    }
   ],
   "source": [
    "y_trues = np.array(test_data['is_multiple'])\n",
    "preds = best_mult_model.predict_proba(test_data['text'])[:,1]\n",
    "mult_errors = (preds > .5) != y_trues\n",
    "\n",
    "mult_error_df = pd.DataFrame({\n",
    "        'text':np.array(test_data['text'])[mult_errors],\n",
    "        'y_true':y_trues[mult_errors],\n",
    "        'prob':preds[mult_errors],\n",
    "        'is_biased':np.array(test_data['is_biased'])[mult_errors]\n",
    "    })\n",
    "mult_error_df['error_type'] = \"\"\n",
    "mult_error_df['comments'] = \"\"\n",
    "print len(mult_error_df), ' to analyze'\n",
    "# shuffle them and do as many as possible\n",
    "mult_error_df = mult_error_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "mult_error_df.to_excel('mult_errors_to_analyze.xlsx', encoding=\"utf8\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sick Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lr_sick_biased_errors = best_sick_lr_biased.predict(test_data['text']) != y_trues\n",
    "lr_sick_gold_errors = best_sick_lr_gold.predict(test_data['text']) != y_trues\n",
    "lr_sick_silver_errors = best_sick_lr_silver.predict(test_data['text']) != y_trues\n",
    "\n",
    "rf_sick_biased_errors = best_sick_rf_biased.predict(test_data['text']) != y_trues\n",
    "rf_sick_gold_errors = best_sick_rf_gold.predict(test_data['text']) != y_trues\n",
    "rf_sick_silver_errors = best_sick_rf_silver.predict(test_data['text']) != y_trues\n",
    "\n",
    "svm_sick_biased_errors = best_sick_svm_biased.predict(test_data['text']) != y_trues\n",
    "svm_sick_gold_errors = best_sick_svm_gold.predict(test_data['text']) != y_trues\n",
    "svm_sick_silver_errors = best_sick_svm_silver.predict(test_data['text']) != y_trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = pd.DataFrame({\n",
    "        'lr_sick_biased':lr_sick_biased_errors,\n",
    "        'lr_sick_gold':lr_sick_gold_errors,\n",
    "        'lr_sick_silver':lr_sick_silver_errors,\n",
    "        'rf_sick_biased':rf_sick_biased_errors,\n",
    "        'rf_sick_gold':rf_sick_gold_errors,\n",
    "        'rf_sick_silver':rf_sick_silver_errors,\n",
    "        'svm_sick_biased':svm_sick_biased_errors,\n",
    "        'svm_sick_gold':svm_sick_gold_errors,\n",
    "        'svm_sick_silver':svm_sick_silver_errors,\n",
    "        'true_label':y_trues,\n",
    "        'is_biased':test_data['is_biased'],\n",
    "        'text':test_data['text']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    2628\n",
      "True      347\n",
      "Name: lr_sick_biased, dtype: int64\n",
      "\n",
      "False    2670\n",
      "True      305\n",
      "Name: lr_sick_gold, dtype: int64\n",
      "\n",
      "False    2678\n",
      "True      297\n",
      "Name: lr_sick_silver, dtype: int64\n",
      "\n",
      "False    2532\n",
      "True      443\n",
      "Name: rf_sick_biased, dtype: int64\n",
      "\n",
      "False    2606\n",
      "True      369\n",
      "Name: rf_sick_gold, dtype: int64\n",
      "\n",
      "False    2631\n",
      "True      344\n",
      "Name: rf_sick_silver, dtype: int64\n",
      "\n",
      "False    2387\n",
      "True      588\n",
      "Name: svm_sick_biased, dtype: int64\n",
      "\n",
      "False    2656\n",
      "True      319\n",
      "Name: svm_sick_gold, dtype: int64\n",
      "\n",
      "False    2026\n",
      "True      949\n",
      "Name: svm_sick_silver, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in errors.columns:\n",
    "    if 'sick' in col:\n",
    "        print errors[col].value_counts()\n",
    "        print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors['total'] = errors.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x18e7f31d0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqgAAAHoCAYAAACFCB2tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19fb4a4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts, bin_edges, _ = plt.hist(errors.total, bins=np.arange(11))\n",
    "plt.xticks(np.arange(10))\n",
    "plt.title('Classification Errors Hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1284 examples were mistaken by 0/9 classifiers\n",
      "1030 examples were mistaken by 1/9 classifiers\n",
      "173 examples were mistaken by 2/9 classifiers\n",
      "123 examples were mistaken by 3/9 classifiers\n",
      "95 examples were mistaken by 4/9 classifiers\n",
      "68 examples were mistaken by 5/9 classifiers\n",
      "45 examples were mistaken by 6/9 classifiers\n",
      "52 examples were mistaken by 7/9 classifiers\n",
      "83 examples were mistaken by 8/9 classifiers\n",
      "22 examples were mistaken by 9/9 classifiers\n"
     ]
    }
   ],
   "source": [
    "for i, count in zip(range(len(counts)), counts):\n",
    "    print '{} examples were mistaken by {}/9 classifiers'.format(int(count), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors[errors['total'] == ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
