{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is just to take in xls/xlsx files and write out csv's for normal use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "### NOW THESE TAKE CELL OBJECTS INSTEAD OF THE CELL VALUES BECAUSE OF DATES\n",
    "def xuni(cell):\n",
    "    # handle numerics\n",
    "    # handle weird fucking xlrd excel dates\n",
    "    s=cell.value\n",
    "    if cell.ctype == xlrd.XL_CELL_DATE:\n",
    "        date = datetime.datetime(1899, 12, 30)\n",
    "        get_ = datetime.timedelta(int(cell.value))\n",
    "        get_col2 = str(date + get_)[:10]\n",
    "        d = datetime.datetime.strptime(get_col2, '%Y-%m-%d')\n",
    "        get_col = d.strftime('%Y-%m-%d')\n",
    "        return get_col\n",
    "    \n",
    "    elif type(s) == float:\n",
    "        return s\n",
    "    elif type(s) == int:\n",
    "        return s\n",
    "    elif not s:\n",
    "        return u''\n",
    "    elif type(s) == unicode:\n",
    "        return s.encode('utf-8')\n",
    "    elif type(s) == str:\n",
    "        return unicode(s, 'utf-8')\n",
    "    else: \n",
    "        return s\n",
    "    \n",
    "def xstr(cell):\n",
    "    # handle numerics\n",
    "    # handle weird fucking xlrd excel dates\n",
    "    s=cell.value\n",
    "    if cell.ctype == xlrd.XL_CELL_DATE:\n",
    "        date = datetime.datetime(1899, 12, 30)\n",
    "        get_ = datetime.timedelta(int(cell.value))\n",
    "        get_col2 = str(date + get_)[:10]\n",
    "        d = datetime.datetime.strptime(get_col2, '%Y-%m-%d')\n",
    "        get_col = d.strftime('%Y-%m-%d')\n",
    "        return get_col\n",
    "    elif type(s) == float:\n",
    "        return s\n",
    "    elif type(s) == int:\n",
    "        return s\n",
    "    elif not s:\n",
    "        return ''\n",
    "    elif type(s) == unicode:\n",
    "        return str(s)\n",
    "    elif type(s) == str:\n",
    "        return s\n",
    "    else: \n",
    "        return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import openpyxl\n",
    "import xlrd\n",
    "\n",
    "def write_excel_to_csv(filename, sheet_index=0, strip_newline=True, unicode=True, outname=None):\n",
    "    \"\"\"If you want to write out a different sheet than the first, input the sheet index (from 0)\n",
    "        outname is the file name WITHOUT .csv\"\"\"\n",
    "    split = filename.split('.')\n",
    "    ext = split[-1]\n",
    "    if ext == 'xlsx':\n",
    "        if outname:\n",
    "            fname = outname\n",
    "        else:\n",
    "            fname = '.'.join(split[:-1])\n",
    "        wb = openpyxl.load_workbook(filename)\n",
    "        sh = wb.worksheets[sheet_index]\n",
    "        with open(fname + '.csv', 'wb') as f:\n",
    "            c = csv.writer(f)\n",
    "            for r in sh.rows:\n",
    "                if strip_newline:\n",
    "                    if unicode:\n",
    "                        line = [xuni(cell).strip('\\n').strip('\\r') for cell in r]\n",
    "                    else:\n",
    "                        line = [xstr(cell).strip('\\n').strip('\\r') for cell in r]\n",
    "                else:\n",
    "                    if unicode:\n",
    "                        line = [xuni(cell) for cell in r]\n",
    "                    else:\n",
    "                        line = [xstr(cell) for cell in r]\n",
    "                c.writerow(line)\n",
    "        return fname+'.csv'\n",
    "    elif ext == 'xls':\n",
    "        if outname:\n",
    "            fname = outname\n",
    "        else:\n",
    "            fname = '.'.join(split[:-1])\n",
    "        wb = xlrd.open_workbook(filename)\n",
    "        sh = wb.sheet_by_index(sheet_index)\n",
    "        with open(fname + '.csv', 'wb') as f:\n",
    "            c = csv.writer(f)\n",
    "            num_cols = sh.ncols   # Number of columns\n",
    "            for row_idx in range(0, sh.nrows):\n",
    "                if strip_newline:\n",
    "                    if unicode:\n",
    "                        line = [xuni(sh.cell(row_idx, col_idx)).strip('\\n').strip('\\r') for col_idx in range(0, num_cols)]\n",
    "                    else:\n",
    "                        line = [xstr(sh.cell(row_idx, col_idx)).strip('\\n').strip('\\r') for col_idx in range(0, num_cols)]\n",
    "                else:\n",
    "                    if unicode:\n",
    "                        line = [xuni(sh.cell(row_idx, col_idx)) for col_idx in range(0, num_cols)]\n",
    "                    else:\n",
    "                        line = [xstr(sh.cell(row_idx, col_idx)) for col_idx in range(0, num_cols)]\n",
    "                c.writerow(line)\n",
    "        return fname+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def csv_col_names(csvfile):\n",
    "    with open(csvfile, 'rU') as f:\n",
    "        reader = csv.reader(f)\n",
    "        headers = reader.next()    \n",
    "    return headers\n",
    "\n",
    "def write_select_columns_to_csv(infile, outfile, colnames):\n",
    "    \"\"\" Takes a csv file, outputs a csv file with cols columns \n",
    "        NOTE: ASSUMES THE FIRST LINE IS ALWAYS THE HEADER\"\"\"\n",
    "    if infile.split('.')[-1] != 'csv':\n",
    "        print \"INPUT NEEDS TO BE CSV. EXITING\"\n",
    "        return\n",
    "    with open(infile, 'rU') as f:\n",
    "        reader = csv.reader(f)\n",
    "        with open(outfile, 'w') as w:\n",
    "            writer = csv.writer(w)\n",
    "            col_is = []\n",
    "            for i, row in enumerate(reader):\n",
    "                if i == 0: # headers\n",
    "                    col_is = [ row.index(coln) for coln in colnames]\n",
    "                    writer.writerow(colnames)\n",
    "                    continue\n",
    "                # rest of the data\n",
    "                newrow = [ row[col_i] for col_i in col_is ]\n",
    "                writer.writerow(newrow)\n",
    "    print \"DONE\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '.ipynb_checkpoints',\n",
       " 'chromeremotedesktop.dmg',\n",
       " 'CSV Writer.ipynb',\n",
       " 'disclda-discriminative-learning-for-dimensionality-reduction-and-classification.bib',\n",
       " 'DiscLDA.ipynb',\n",
       " 'Doc Embeddings Presi.ipynb',\n",
       " 'Evaluation Sample.ipynb',\n",
       " 'Foodborne Twitter Tests.ipynb',\n",
       " 'kdd2011-pldp-final.pdf',\n",
       " 'Labeled Tweets Analysis.ipynb',\n",
       " 'LDA 2.ipynb',\n",
       " 'LDA.ipynb',\n",
       " 'lda_boxplot_2500_7500.pdf',\n",
       " 'lda_boxplot_drown.pdf',\n",
       " 'lda_boxplot_drown_5.pdf',\n",
       " 'lda_boxplot_drown_6.pdf',\n",
       " 'lda_boxplot_drown_6.png',\n",
       " 'ml_example.zip',\n",
       " 'pull_yelp.xlsx',\n",
       " 'pull_yelp_raw.csv',\n",
       " 'PyHealth test.ipynb',\n",
       " 'reviews_foodborne.csv',\n",
       " 'reviews_foodborne_date_biz.csv',\n",
       " 'stream_incidents1.json',\n",
       " 'stream_tweets1.json',\n",
       " 'Twitter sandbox.ipynb',\n",
       " 'Twitter Stream.ipynb',\n",
       " 'Yelp Reviews_dataset for paper data for Fotis.xlsx',\n",
       " 'Yelp Sandbox.ipynb',\n",
       " 'yelp_annotated_analysis.csv',\n",
       " 'yelp_annotated_analysis.xls',\n",
       " 'yelp_mult_data.xlsx']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_annotated_analysis.csv\n",
      "HEADERS: ['ID', 'Date_Review', 'URL', 'User', 'Business', 'Review', 'Keyword', 'Sick', 'Sick_2', 'Multiple', 'Incubation', 'Interest', 'Score', 'Foodborne_Disease', 'Occurred_Less_Than_4_Weeks', '2_Or_More_Ill', 'Severe_Illness_Occur', 'Action_Item', '311_Report', 'FoodborneAsBoolean', 'NumIsSick']\n"
     ]
    }
   ],
   "source": [
    "og_file = 'yelp_annotated_analysis.xls'\n",
    "incsv = write_excel_to_csv(og_file, sheet_index=6, strip_newline = False)\n",
    "print incsv\n",
    "cols = csv_col_names(incsv)\n",
    "print \"HEADERS: %r\" % cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "mycols = ['Review', 'FoodborneAsBoolean', 'Date_Review', 'Business']\n",
    "outfile = \"reviews_foodborne_date_biz.csv\"\n",
    "infname = 'yelp_annotated_analysis.csv'\n",
    "write_select_columns_to_csv(infname, outfile, mycols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
